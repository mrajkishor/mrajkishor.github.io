
# ğŸš€ Mastering Dynamic Programming (DP): Use Cases & Patterns

Dynamic Programming (DP) is one of the most powerful algorithmic techniques in problem-solving interviews and competitive programming. If youâ€™ve ever solved a problem and thought, â€œIâ€™m recalculating the same thing again and again,â€ then **DP is your friend**.

---

## ğŸ¯ What Is Dynamic Programming?

Dynamic Programming is an optimization technique used to **avoid redundant calculations** by storing results of subproblems and reusing them when needed.

It applies when:
- **The problem has overlapping subproblems**
- **The problem has optimal substructure** (solution can be built from solutions of subproblems)

---

## ğŸ§© Two Core Techniques in DP

### 1ï¸âƒ£ Top-Down Approach (Memoization)
- Solve the main problem by **recursively solving subproblems**
- Store answers in a **map or array** to avoid recomputation

```java
// Java Example: Fibonacci with memoization
Map<Integer, Integer> memo = new HashMap<>();

int fib(int n) {
    if (n <= 1) return n;
    if (memo.containsKey(n)) return memo.get(n);
    int result = fib(n - 1) + fib(n - 2);
    memo.put(n, result);
    return result;
}
```

---

### 2ï¸âƒ£ Bottom-Up Approach (Tabulation)
- **Start from the base case** and iteratively build up the solution
- Avoids recursion (better space and performance)

```java
// Java Example: Fibonacci with tabulation
int fib(int n) {
    if (n <= 1) return n;
    int[] dp = new int[n + 1];
    dp[0] = 0; dp[1] = 1;
    for (int i = 2; i <= n; i++)
        dp[i] = dp[i - 1] + dp[i - 2];
    return dp[n];
}
```

---

## ğŸ’¡ When to Use DP â€“ Common Use Cases

### ğŸ§  Optimal Choices / Overlapping Subproblems
Problems where you must make a choice at each step and future outcomes depend on that decision.  
**Examples:** Fibonacci, Climbing Stairs, Min Cost Climbing

---

### ğŸ’ 1. Knapsack / Subset Problems
These involve choices with weights or values:
- **0/1 Knapsack** â€“ Choose items with or without including them
- **Subset Sum** â€“ Is there a subset with a given sum?

ğŸ‘‰ Use a **2D or 1D DP array** based on space optimization.

---

### âœ‚ï¸ 2. Edit Distance / Longest Common Subsequence (LCS)
Used in string transformation problems:
- **Edit Distance** â€“ Min operations to convert one string to another
- **LCS** â€“ Longest subsequence common to both strings

ğŸ‘‰ Use **DP Matrix** (`dp[i][j]`) where `i` and `j` are string indices.

---

### ğŸ’° 3. Coin Change Variants
- **Minimum coins to make amount**
- **Count ways to make amount**

ğŸ‘‰ Recurrence builds upon combinations of coin denominations.

---

### ğŸ“¦ 4. Partition Problems
- Equal Partition of array
- Maximize the minimum difference

ğŸ‘‰ Reduces to **subset sum variations**.

---

### â›ï¸ 5. Cutting Problems
- **Rod Cutting** â€“ Max revenue from rod pieces
- **Palindrome Partitioning** â€“ Min cuts to make all substrings palindromic

ğŸ‘‰ Requires splitting at multiple points and checking combinations.

---

### ğŸ“ˆ 6. Maximum Subarray Sum â€“ Kadaneâ€™s Algorithm
- Tracks `localMax` and updates `globalMax`
- Classic problem: [Leetcode #53](https://leetcode.com/problems/maximum-subarray/)

```java
int maxSubArray(int[] nums) {
    int currentMax = nums[0], globalMax = nums[0];
    for (int i = 1; i < nums.length; i++) {
        currentMax = Math.max(nums[i], currentMax + nums[i]);
        globalMax = Math.max(globalMax, currentMax);
    }
    return globalMax;
}
```

---

## ğŸ” How to Recognize a DP Problem

Ask:
- Can I divide the problem into **smaller overlapping subproblems**?
- Does the final answer **depend on previous states**?
- Are there **too many recursive calls** (causing TLE)?  
If yes, itâ€™s time to **switch to DP**.

---

## âœ… Final Tip: Build a Template
1. Define state (`dp[i]` or `dp[i][j]`)
2. Define base cases
3. Write recurrence
4. Implement in top-down or bottom-up
5. Optimize space if needed

---

## ğŸ§ª Practice Problems
| Problem | Type |
|--------|------|
| Climbing Stairs | Fibonacci-style |
| House Robber | Linear DP |
| Longest Palindromic Substring | 2D DP |
| Subset Sum | Knapsack |
| Edit Distance | DP Matrix |

---

#### Q. Why memoisation is not used in tabulation?

Here's the clear reasoning:

---

### ğŸ” **Memoization vs. Tabulation**

| Aspect | Memoization (Top-Down) | Tabulation (Bottom-Up) |
|--------|------------------------|-------------------------|
| Style | Recursive | Iterative |
| How It Works | Calls subproblems on-demand, caches results | Precomputes all subproblems |
| Cache Use | Only when needed | Fills whole table regardless |
| Flow | From main problem â†’ base case | From base case â†’ main problem |

---

### ğŸ’¡ **Why Memoization is *not* used in Tabulation**

Because **tabulation computes everything in order from the bottom**, there is **no need to check** whether a value was already computed (like memoization does). You're controlling the flow step-by-step.

> In memoization, you ask: "Did I solve this subproblem before?"  
> In tabulation, you say: "Let me solve **every** subproblem in order."

---

### ğŸ” Analogy

Memoization = Lazy evaluation (only when required)  
Tabulation = Eager evaluation (compute all up front)

---

So, memoization is not used in tabulation because:
- Tabulation ensures all required subproblems are already computed when needed
- Thereâ€™s no recursive call stack to trigger lazy lookup
- Itâ€™s redundant and inefficient to check for previously filled values in a loop

---

#### Q. Which is better approach (memoisation or tabulation) ?


Hereâ€™s a quick comparison to help decide which approach is better:

---

### ğŸ§® **Memoization (Top-Down)**
- âœ… Good when **only some subproblems** are needed
- âœ… Easier to write recursively
- âŒ Can cause **stack overflow** if recursion depth is high
- âœ… Great for problems with **sparse overlapping subproblems**

---

### ğŸ§± **Tabulation (Bottom-Up)**
- âœ… Avoids recursion â†’ **no stack overflow**
- âœ… Usually **faster** in practice due to tight loops
- âœ… Ideal when **all subproblems** are needed
- âœ… **Easier to optimize space**

---

### ğŸ” Verdict

| Use Case                              | Better Approach       |
|---------------------------------------|------------------------|
| Deep recursion or space optimization  | **Tabulation**         |
| Partial computation or branching      | **Memoization**        |
| Large input size                      | **Tabulation**         |
| Learning or debugging                 | **Memoization** (easier to trace) |

---

**ğŸ‘‰ In interviews**: Start with memoization for clarity, switch to tabulation if performance or space becomes critical.

---

==A List of **Dynamic Programming problems** that specifically involve **optimal choices and overlapping subproblems** â€” perfect for mastering both memoization and tabulation:==



### ğŸ¯ **Optimal Choices / Overlapping Subproblems â€“ Problem List**

| # | Problem Name | Platform | Pattern |
|---|--------------|----------|---------|
| 1ï¸âƒ£ | [Climbing Stairs](https://leetcode.com/problems/climbing-stairs/) | LeetCode | Fibonacci-style DP |
| 2ï¸âƒ£ | [House Robber](https://leetcode.com/problems/house-robber/) | LeetCode | Choose/Skip Pattern |
| 3ï¸âƒ£ | [House Robber II](https://leetcode.com/problems/house-robber-ii/) | LeetCode | Circular DP |
| 4ï¸âƒ£ | [Paint House](https://leetcode.com/problems/paint-house/) | LeetCode | Min Cost |
| 5ï¸âƒ£ | [Partition Equal Subset Sum](https://leetcode.com/problems/partition-equal-subset-sum/) | LeetCode | Subset Sum DP |
| 6ï¸âƒ£ | [Coin Change](https://leetcode.com/problems/coin-change/) | LeetCode | Minimize Coins |
| 7ï¸âƒ£ | [Coin Change II](https://leetcode.com/problems/coin-change-ii/) | LeetCode | Count Ways |
| 8ï¸âƒ£ | [0/1 Knapsack Problem](https://practice.geeksforgeeks.org/problems/0-1-knapsack-problem0945/1) | GFG | Classic Choice DP |
| 9ï¸âƒ£ | [Unbounded Knapsack](https://www.geeksforgeeks.org/unbounded-knapsack-repetition-items-allowed/) | GFG | Reuse Items |
| ğŸ”Ÿ | [Minimum Path Sum](https://leetcode.com/problems/minimum-path-sum/) | LeetCode | Grid Path DP |

---

### ğŸ“š String-Based Optimal Choice DP

| # | Problem Name | Platform | Pattern |
|---|--------------|----------|---------|
| 1ï¸âƒ£1ï¸âƒ£ | [Longest Common Subsequence](https://leetcode.com/problems/longest-common-subsequence/) | LeetCode | 2D DP |
| 1ï¸âƒ£2ï¸âƒ£ | [Longest Palindromic Subsequence](https://leetcode.com/problems/longest-palindromic-subsequence/) | LeetCode | Choice between ends |
| 1ï¸âƒ£3ï¸âƒ£ | [Edit Distance](https://leetcode.com/problems/edit-distance/) | LeetCode | Insert/Delete/Replace |
| 1ï¸âƒ£4ï¸âƒ£ | [Palindrome Partitioning II](https://leetcode.com/problems/palindrome-partitioning-ii/) | LeetCode | Min Cut |
| 1ï¸âƒ£5ï¸âƒ£ | [Distinct Subsequences](https://leetcode.com/problems/distinct-subsequences/) | LeetCode | Include/Exclude |
| 1ï¸âƒ£6ï¸âƒ£ | [Interleaving String](https://leetcode.com/problems/interleaving-string/) | LeetCode | Merge 2 strings |

---

### âš™ï¸ Matrix / Game / State Transition DP

| # | Problem Name | Platform | Pattern |
|---|--------------|----------|---------|
| 1ï¸âƒ£7ï¸âƒ£ | [Burst Balloons](https://leetcode.com/problems/burst-balloons/) | LeetCode | Interval DP |
| 1ï¸âƒ£8ï¸âƒ£ | [Matrix Chain Multiplication](https://www.geeksforgeeks.org/matrix-chain-multiplication-dp-8/) | GFG | Parenthesization |
| 1ï¸âƒ£9ï¸âƒ£ | [Stone Game](https://leetcode.com/problems/stone-game/) | LeetCode | MinMax DP |
| 2ï¸âƒ£0ï¸âƒ£ | [Minimum Cost Tree From Leaf Values](https://leetcode.com/problems/minimum-cost-tree-from-leaf-values/) | LeetCode | Divide & Conquer |

---

**Note:**

âœ… **Tabulation usually takes more space than recursion** â€” *unless* you optimize it.


### ğŸ“Š Tabulation (Bottom-Up)
- Uses an **array or matrix** to store *all* subproblem results.
- So it takes **O(n)** or **O(nÃ—m)** space depending on the problem.

---

### ğŸ” Recursion with Memoization (Top-Down)
- Uses a **cache + call stack**:
  - Cache: stores results â†’ O(n)
  - Call stack: adds extra space â†’ O(n) worst case

---

### ğŸ”„ Pure Recursion (No Memoization)
- Uses **only stack space**, but leads to **exponential time** and possibly stack overflow.

---

### ğŸ§  Optimization Tip
Many tabulation problems can be **space optimized**:
- **Fibonacci:** from `O(n)` â†’ `O(1)`
- **2D DP problems (e.g. LCS):** from `O(nÃ—m)` â†’ `O(min(n, m))`

---

### âœ… Final Verdict

| Approach         | Space Complexity |
|------------------|------------------|
| Tabulation       | âœ… Predictable but higher (O(n), O(nÃ—m)) |
| Memoization      | âš ï¸ Depends on recursion depth + cache |
| Space-Optimized Tabulation | âœ… Best of both (O(1), O(n)) |

---

**Tabulation may use more space**, but it's **safer and more stack-friendly** than deep recursion.

### ğŸ”§ How Tabulation Space is Optimized

Instead of storing **all subproblems**, we observe that:
> Most DP problems only need the **last few states**, not the entire table.

So we can **reduce space** by storing only what's necessary.

---

### âœ… Common Techniques

#### 1ï¸âƒ£ **Rolling Array (1D Optimization)**
Use two variables or a small array instead of the full `dp[]`.

**Example: Fibonacci**
```java
int fib(int n) {
    if (n <= 1) return n;
    int prev2 = 0, prev1 = 1, curr = 0;
    for (int i = 2; i <= n; i++) {
        curr = prev1 + prev2;
        prev2 = prev1;
        prev1 = curr;
    }
    return curr;
}
```
ğŸ§  From `O(n)` â†’ `O(1)` space

---

#### 2ï¸âƒ£ **Row Compression (2D â†’ 1D)**
Use one or two rows in problems like LCS, Edit Distance, Knapsack.

**Example: LCS**
```java
int lcs(String a, String b) {
    int[] prev = new int[b.length() + 1];
    int[] curr = new int[b.length() + 1];

    for (int i = 1; i <= a.length(); i++) {
        for (int j = 1; j <= b.length(); j++) {
            curr[j] = a.charAt(i-1) == b.charAt(j-1) 
                      ? 1 + prev[j-1] 
                      : Math.max(prev[j], curr[j-1]);
        }
        int[] temp = prev;
        prev = curr;
        curr = temp;
    }
    return prev[b.length()];
}
```
ğŸ§  From `O(nÃ—m)` â†’ `O(m)`

---

#### 3ï¸âƒ£ **In-Place Updates**
When updates donâ€™t interfere, reuse the same array for both reads and writes.

---

### ğŸ“Œ Summary Table

| Optimization | Use Case | From | To |
|--------------|----------|------|----|
| Rolling Variables | Linear DP (Fibonacci, Staircase) | O(n) | O(1) |
| Row Compression | 2D DP (LCS, Knapsack) | O(nÃ—m) | O(min(n,m)) |
| In-Place DP | Safe overwrite (like Prefix Sum problems) | O(n) | O(1) |


---


## Q. Does memoisation uses more stack spaces while tabulation uses more heap space?



### ğŸ§  **Memoization**
- ğŸ“Œ **Top-down recursive**
- ğŸ—‚ï¸ Uses **call stack** â†’ occupies **stack memory**
- ğŸ§¾ Stores results in a cache (map/array) â†’ uses **heap memory**
- âŒ Deep recursion = **stack overflow risk**

---

### ğŸ“Š **Tabulation**
- ğŸ“Œ **Bottom-up iterative**
- ğŸ” No recursion â†’ minimal **stack memory**
- ğŸ§¾ Uses a full DP table in **heap memory**
- âœ… Safer for large input sizes

---

### âš–ï¸ Summary Table

| Approach     | Stack Memory        | Heap Memory        | Risk |
|--------------|---------------------|---------------------|------|
| Memoization  | ğŸ”¼ High (recursive)  | âœ… Medium (cache)   | âš ï¸ Stack Overflow |
| Tabulation   | âœ… Low (iterative)   | ğŸ”¼ Higher (DP table) | âœ… Safe |

---

ğŸ’¡ So yes:
> **Memoization = more stack memory**  
> **Tabulation = more heap memory**

---

### Q. Why stack memory is easily overflowed but not heap?

Great question! Here's the intuitive and technical answer:

---

### ğŸ§  **Stack Memory vs Heap Memory â€” Why Stack Overflows Easily**

| Feature            | **Stack**                             | **Heap**                            |
|--------------------|----------------------------------------|-------------------------------------|
| ğŸ’¾ Size Limit      | **Very small** (typically 1â€“2 MB per thread) | **Very large** (can be GBs)         |
| ğŸŒ€ Purpose          | Stores **function call frames**        | Stores **objects and data**         |
| â±ï¸ Allocation Speed | **Very fast** (LIFO)                   | Slower (managed by GC)              |
| ğŸ”¥ Overflow Risk   | **High** (deep recursion)              | Low (unless memory leak)            |
| ğŸ”„ Lifetime         | Auto-freed after function returns      | Freed by Garbage Collector (GC)     |

---

### ğŸ” Why Stack Overflows Easily

1. **Fixed small size**: The stack size per thread is limited (e.g., 1MB).
2. **Every recursive call** = one stack frame.
3. So deep recursion (like `fib(100000)`) = ğŸ’¥ stack overflow.

```java
// Stack will overflow if n is too large
int fib(int n) {
    if (n <= 1) return n;
    return fib(n - 1) + fib(n - 2);
}
```

---

### ğŸ“¦ Why Heap Doesnâ€™t Overflow Easily

- **Much bigger** â€” often **GBs** in size (configurable with `-Xmx`)
- Allocated for objects and data (like `new int[1000000]`)
- Managed by the **Garbage Collector (GC)**

```java
int[] dp = new int[1000000]; // Heap stores this, and itâ€™s okay
```

---

### ğŸ§ª Example in Java

```bash
java -Xss512k MyStackProgram  # Stack size = 512 KB
java -Xmx2G MyHeapProgram     # Heap size = 2 GB
```

---

### ğŸ§  Conclusion

> âœ… Heap = Big, Flexible, GC-managed â†’ Hard to overflow  
> âŒ Stack = Small, Per-thread, Recursive calls â†’ Easy to overflow

---

ğŸ” **Why only 1â€“2 MB stack memory per thread?**

Because the **stack is fixed-size memory** allocated at thread creation, and keeping it small helps ensure:

---

### ğŸ§  1. **Memory Efficiency**
- Every thread gets its own stack.
- If each thread got, say, 100 MB â†’ 1,000 threads = ğŸ’¥ 100 GB used.
- Keeping stack small (e.g. 1 MB) allows **thousands of threads** to run concurrently.

---

### ğŸ§° 2. **Faster Allocation**
- Stack memory is managed using **simple pointer arithmetic (LIFO)**.
- Small size â†’ quick allocation & deallocation â†’ **faster than heap**.

---

### ğŸ’¥ 3. **Avoid Crashes from Uncontrolled Recursion**
- Small size prevents infinite/very deep recursion from crashing the whole system.
- You get a **StackOverflowError** instead of system freeze.

---

### âš™ï¸ 4. **OS/Architecture Limits**
- OS and CPU architecture have limits on per-thread memory regions.
- Exceeding this causes **segmentation faults** or undefined behavior.

---

### ğŸ› ï¸ Bonus: You *Can* Change It (with care)

In Java:
```bash
java -Xss2m MyProgram   // 2 MB stack
```

In C/C++ (POSIX):
```cpp
pthread_attr_setstacksize(&attr, 2 * 1024 * 1024);  // Set to 2MB
```

But increasing it too much can reduce the number of threads your app can create.

---

### âœ… Summary

> Stack is small **by design** to save memory, ensure performance, and prevent abuse.  
> If you need more space, prefer **tabulation or tail recursion optimization.**





