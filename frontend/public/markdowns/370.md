# **Bounded Contexts & Aggregates**  

## **🚀 Introduction**  
Designing microservices requires a structured approach to ensure scalability, maintainability, and independence between services. **Domain-Driven Design (DDD)** provides essential concepts like **Bounded Contexts** and **Aggregates** to help **organize services logically and maintain a clean domain model**.  

In this blog, we’ll cover:  
- **What is a Bounded Context?**  
- **Why Bounded Contexts are Important in Microservices**  
- **What is an Aggregate?**  
- **How Aggregates Ensure Consistency**  
- **Best Practices for Defining Bounded Contexts & Aggregates**  

---

## **📌 What is a Bounded Context?**  
A **Bounded Context** is a **logical boundary** within a domain where a specific model is applied. Each microservice represents a **separate bounded context** with **its own business logic, domain model, and database**.  

### **🔹 Example: Bounded Contexts in an E-Commerce System**  
An e-commerce system may have the following **bounded contexts (separate microservices)**:  
- **Order Service** → Manages orders, payments, and shipment tracking.  
- **Inventory Service** → Tracks product availability and stock levels.  
- **Customer Service** → Stores user profiles, addresses, and preferences.  
- **Payment Service** → Processes transactions and refunds.  

Each service **defines its own data model** and doesn’t share databases, ensuring **clear separation of concerns**.

### **🔹 Why Bounded Contexts Are Important in Microservices**
✅ **Avoids Data Coupling** – Each service **owns its own data model** (no direct database sharing).  
✅ **Improves Maintainability** – Changes in one service don’t affect others.  
✅ **Enhances Scalability** – Each bounded context can be **deployed and scaled independently**.  
✅ **Reduces Complexity** – Prevents a **distributed monolith** by enforcing service boundaries.  

---

## **📌 What is an Aggregate?**  
An **Aggregate** is a **group of related domain objects** that should be treated as a **single unit** when making changes.  

An **Aggregate Root** is the **main entity** that ensures consistency **within the aggregate**. External services can only interact with the **aggregate root** and not directly with internal objects.  

### **🔹 Example: Aggregate in an Order Service**
The **Order Aggregate** consists of:  
- **Order (Aggregate Root)** – The main entity representing an order.  
- **Order Items** – Line items associated with an order.  
- **Payment Details** – Stores payment confirmation details.  

📌 **Rule:** Any changes within the aggregate **must go through the aggregate root**.

#### **Java Example: Order Aggregate**
```java
@Entity
public class Order {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String status; // PENDING, PAID, SHIPPED
    
    @OneToMany(cascade = CascadeType.ALL, mappedBy = "order")
    private List<OrderItem> items;
}
```
- The **Order** entity is the **Aggregate Root**.
- `OrderItem` objects are **part of the aggregate** and cannot be modified directly.

---

## **📌 How Aggregates Ensure Consistency in Microservices**
Aggregates **help maintain consistency** by enforcing the following rules:  

✅ **Encapsulation:** Aggregates **hide internal details** from other services.  
✅ **Transaction Boundary:** Changes to an aggregate should be **atomic** (use a single transaction).  
✅ **Event-Driven Updates:** Instead of direct updates, aggregates **emit domain events** for external services.  

---

## **📌 Best Practices for Defining Bounded Contexts & Aggregates**
### **1️⃣ Identify Business Capabilities as Bounded Contexts**
- Use **Event Storming** or **Domain Modeling** to define boundaries.
- Assign **clear ownership** of data to each microservice.

✅ **Example:**
- **Customer Service** owns customer profiles.
- **Order Service** owns order history.
- **Payment Service** owns payment transactions.

---

### **2️⃣ Keep Aggregates Small**
- An aggregate **should only include tightly related objects**.  
- Large aggregates **cause performance issues** and reduce flexibility.  

🚫 **Bad Example:**  
```java
@Entity
public class Order {
    @OneToMany(cascade = CascadeType.ALL)
    private List<Product> products; // ❌ Products should belong to Inventory Service
}
```
✅ **Good Example:**  
```java
@Entity
public class Order {
    @OneToMany(cascade = CascadeType.ALL)
    private List<OrderItem> items; // ✅ OrderItems belong to the Order Aggregate
}
```

---

### **3️⃣ Use Domain Events to Ensure Loose Coupling**
Instead of directly updating another microservice, **emit an event** when something changes.

#### **Example: OrderCreatedEvent (Kafka)**
```java
public class OrderCreatedEvent {
    private Long orderId;
    private Double totalAmount;
}
```
```java
kafkaTemplate.send("order-events", new OrderCreatedEvent(order.getId(), order.getTotal()));
```
- Other services (e.g., **Payment Service**) listen to this event and **react accordingly**.

---

### **4️⃣ Ensure Aggregates Follow the Single Responsibility Principle**
🚫 **Bad Example (Too Many Responsibilities in One Aggregate)**  
```java
@Entity
public class Order {
    @OneToMany
    private List<OrderItem> items;

    @OneToOne
    private PaymentDetails payment; // ❌ Payment should belong to Payment Service

    @OneToOne
    private ShippingDetails shipping; // ❌ Shipping should belong to Shipment Service
}
```
✅ **Good Example (Separate Responsibilities Across Bounded Contexts)**  
```java
@Entity
public class Order {
    @OneToMany
    private List<OrderItem> items;
}
```
- **PaymentDetails** exists in **Payment Service**.
- **ShippingDetails** exists in **Shipment Service**.

---

## **📌 Conclusion**
**Bounded Contexts and Aggregates** are **essential for designing microservices** that are **scalable, maintainable, and independent**.  

### **🚀 Key Takeaways**
✅ **Bounded Contexts define the boundaries of a microservice**, ensuring data ownership and separation.  
✅ **Aggregates encapsulate related domain objects** and enforce consistency within their boundaries.  
✅ **Aggregates should be small** to improve performance and flexibility.  
✅ **Domain events (Kafka, RabbitMQ) should be used for inter-service communication** instead of direct service calls.  

---

# **Hands-on Guide: Implementing Bounded Contexts & Aggregates in Spring Boot**

In this guide, we will **implement Bounded Contexts and Aggregates** in a **Microservices-based E-Commerce system** using **Spring Boot**. We'll use **REST APIs, JPA for persistence, Kafka for event-driven communication, and Docker for service isolation**.

---

## **📌 Project Overview**
### **🔹 Microservices Architecture**
We will implement **three microservices**, each representing a **Bounded Context**:

1. **Order Service** → Manages orders, order items, and emits `OrderCreatedEvent`.
2. **Payment Service** → Listens for `OrderCreatedEvent`, processes payments, and emits `PaymentSuccessEvent`.
3. **Inventory Service** → Listens for `PaymentSuccessEvent` and updates stock.

📌 **Key Concepts Covered:**
✅ **Bounded Contexts** – Each service has its own **database and domain model**.  
✅ **Aggregates** – **Order Aggregate** in `OrderService`.  
✅ **Event-Driven Communication** – Services **emit and listen to events using Kafka**.  

---

## **📌 Step 1: Setting Up Order Service (Bounded Context: Orders)**
### **🔹 Define the Order Aggregate**
- **Order (Aggregate Root)**
- **OrderItem (Part of the Aggregate)**

#### **📝 Order Entity (Aggregate Root)**
```java
@Entity
public class Order {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String status; // PENDING, PAID, SHIPPED
    private Double totalAmount;

    @OneToMany(cascade = CascadeType.ALL, mappedBy = "order")
    private List<OrderItem> items;

    // Constructor, Getters & Setters
}
```

#### **📝 OrderItem Entity**
```java
@Entity
public class OrderItem {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String productName;
    private Integer quantity;
    private Double price;

    @ManyToOne
    @JoinColumn(name = "order_id")
    private Order order;
}
```
- `Order` is the **Aggregate Root**.
- `OrderItem` is **part of the Order Aggregate** and cannot be modified independently.

---

### **🔹 Define the Order Repository**
```java
@Repository
public interface OrderRepository extends JpaRepository<Order, Long> {
}
```

---

### **🔹 Publish an Event When an Order is Created**
Instead of calling the `Payment Service` directly, we **emit an event** using **Kafka**.

#### **📝 OrderCreatedEvent**
```java
public class OrderCreatedEvent {
    private Long orderId;
    private Double totalAmount;
}
```

#### **📝 Kafka Producer to Publish Event**
```java
@Service
public class OrderService {
    @Autowired private OrderRepository orderRepository;
    @Autowired private KafkaTemplate<String, OrderCreatedEvent> kafkaTemplate;

    public Order createOrder(Order order) {
        order.setStatus("PENDING");
        Order savedOrder = orderRepository.save(order);
        
        // Emit event to Kafka
        kafkaTemplate.send("order-events", new OrderCreatedEvent(savedOrder.getId(), savedOrder.getTotalAmount()));
        
        return savedOrder;
    }
}
```
✅ **Instead of making a direct API call to Payment Service, we publish `OrderCreatedEvent` to Kafka.**

---

## **📌 Step 2: Setting Up Payment Service (Bounded Context: Payments)**
- **Listens for `OrderCreatedEvent`** from Kafka.
- **Processes the payment** and **emits `PaymentSuccessEvent`**.

### **🔹 Kafka Consumer in Payment Service**
```java
@Service
public class PaymentService {
    @Autowired private KafkaTemplate<String, PaymentSuccessEvent> kafkaTemplate;

    @KafkaListener(topics = "order-events", groupId = "payment-group")
    public void processPayment(OrderCreatedEvent event) {
        System.out.println("Processing payment for Order ID: " + event.getOrderId());

        // Payment logic (simulated)
        boolean paymentSuccess = true;

        if (paymentSuccess) {
            kafkaTemplate.send("payment-events", new PaymentSuccessEvent(event.getOrderId(), "SUCCESS"));
        }
    }
}
```

✅ **Payment Service listens to `OrderCreatedEvent`, processes payment, and emits `PaymentSuccessEvent`.**

---

## **📌 Step 3: Setting Up Inventory Service (Bounded Context: Inventory)**
- **Listens for `PaymentSuccessEvent`** from Kafka.
- **Updates stock levels**.

### **🔹 Kafka Consumer in Inventory Service**
```java
@Service
public class InventoryService {
    @KafkaListener(topics = "payment-events", groupId = "inventory-group")
    public void updateStock(PaymentSuccessEvent event) {
        System.out.println("Updating inventory for Order ID: " + event.getOrderId());
    }
}
```

✅ **Inventory Service listens for `PaymentSuccessEvent` and updates stock levels accordingly.**

---

## **📌 Step 4: Setting Up Kafka for Event-Driven Communication**
### **🔹 Kafka Configuration (`application.yml`)**
```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumer:
      group-id: order-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: "*"
```
✅ **Each microservice has a different `group-id`, ensuring independent message processing.**

---

## **📌 Step 5: Running Services with Docker**
We’ll containerize our services using **Docker**.

### **🔹 Dockerfile for Order Service**
```dockerfile
FROM openjdk:17-jdk-slim
COPY target/order-service.jar order-service.jar
ENTRYPOINT ["java", "-jar", "/order-service.jar"]
```
✅ **Repeat this for `payment-service` and `inventory-service`.**

---

### **🔹 Docker-Compose File**
```yaml
version: '3'
services:
  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    depends_on:
      - zookeeper

  order-service:
    build: ./order-service
    ports:
      - "8081:8081"
    depends_on:
      - kafka

  payment-service:
    build: ./payment-service
    ports:
      - "8082:8082"
    depends_on:
      - kafka

  inventory-service:
    build: ./inventory-service
    ports:
      - "8083:8083"
    depends_on:
      - kafka
```
✅ **This configures Zookeeper, Kafka, and all three microservices in containers.**

---

## **📌 Expected Workflow**
1️⃣ **Order Service creates an order** and **publishes `OrderCreatedEvent`** to Kafka.  
2️⃣ **Payment Service listens for `OrderCreatedEvent`**, processes payment, and emits `PaymentSuccessEvent`.  
3️⃣ **Inventory Service listens for `PaymentSuccessEvent`** and updates stock levels.  

✅ **This ensures Bounded Contexts communicate asynchronously without direct dependencies!**

---

## **📌 Final Thoughts**
### **🚀 What We Achieved**
✅ **Designed microservices with Bounded Contexts & Aggregates.**  
✅ **Used Event-Driven Architecture with Kafka.**  
✅ **Implemented asynchronous microservice communication.**  
✅ **Deployed using Docker & Docker Compose.**  

---

# **Extending Microservices with Distributed Tracing & Observability (Zipkin, Jaeger)**  

## **🚀 Introduction**  
When microservices communicate asynchronously using **Kafka**, debugging failures and monitoring performance **become challenging**. To **track service-to-service interactions**, we use **Distributed Tracing and Observability tools** like:  
- **Zipkin** – Distributed tracing system for monitoring microservices.  
- **Jaeger** – OpenTelemetry-based tracing tool for debugging microservices.  
- **Prometheus & Grafana** – Metrics collection and visualization for system performance.  

📌 **In this guide, we will:**  
✅ **Integrate Zipkin and Jaeger into our microservices.**  
✅ **Enable Spring Boot to generate tracing IDs for requests.**  
✅ **Visualize traces in Zipkin UI & Jaeger UI.**  
✅ **Monitor microservices performance using Prometheus & Grafana.**  

---

## **📌 Step 1: Setting Up Distributed Tracing with Zipkin**
### **🔹 Add Dependencies for Zipkin in Each Microservice**
In each microservice (`order-service`, `payment-service`, `inventory-service`), add the following dependencies in `pom.xml`:

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-sleuth-zipkin</artifactId>
</dependency>
```

**What happens here?**
- **Spring Cloud Sleuth** automatically **generates tracing IDs** for requests.
- **Zipkin integration** ensures that traces are sent to the **Zipkin server**.

---

### **🔹 Configure Zipkin in `application.yml`**
In each microservice, update `application.yml`:

```yaml
spring:
  application:
    name: order-service
  zipkin:
    base-url: http://zipkin:9411
  sleuth:
    sampler:
      probability: 1.0  # Sample 100% of requests for tracing
```

---

### **🔹 Run Zipkin using Docker**
Add **Zipkin container** in `docker-compose.yml`:

```yaml
zipkin:
  image: openzipkin/zipkin
  ports:
    - "9411:9411"
```

✅ **Zipkin UI is now available at** `http://localhost:9411`.

---

### **🔹 Testing Zipkin Integration**
Run your microservices and send a request:

```bash
curl -X POST http://localhost:8081/orders
```

Now, go to **Zipkin UI (`http://localhost:9411`)**, and you should see a trace with:
- **Order Service**
- **Payment Service**
- **Inventory Service**

✅ **Zipkin now tracks the entire microservice request flow!** 🎉  

---

## **📌 Step 2: Setting Up Jaeger for Advanced Tracing**
Jaeger is an alternative to Zipkin but offers **better OpenTelemetry support**.

### **🔹 Add Jaeger Dependencies**
In `pom.xml`, replace **Zipkin** with **Jaeger**:

```xml
<dependency>
    <groupId>io.opentracing.contrib</groupId>
    <artifactId>opentracing-spring-jaeger-web-starter</artifactId>
    <version>3.3.0</version>
</dependency>
```

---

### **🔹 Configure Jaeger in `application.yml`**
```yaml
spring:
  application:
    name: order-service
  jaeger:
    service-name: order-service
    sender:
      agent-host: jaeger
      agent-port: 6831
```

---

### **🔹 Run Jaeger with Docker**
Add **Jaeger container** to `docker-compose.yml`:

```yaml
jaeger:
  image: jaegertracing/all-in-one:latest
  ports:
    - "16686:16686"  # Jaeger UI
    - "6831:6831/udp" # Jaeger agent
```

✅ **Jaeger UI is available at** `http://localhost:16686`.  

Now, when requests pass through microservices, **Jaeger tracks the flow with spans and latency metrics**.

---

## **📌 Step 3: Adding Metrics with Prometheus & Grafana**
### **🔹 Add Micrometer & Prometheus Dependencies**
In `pom.xml`, add:

```xml
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

---

### **🔹 Configure Prometheus in `application.yml`**
```yaml
management:
  endpoints:
    web:
      exposure:
        include: health, metrics, prometheus
  metrics:
    export:
      prometheus:
        enabled: true
```

✅ **Each microservice now exposes Prometheus metrics at** `http://localhost:8081/actuator/prometheus`.

---

### **🔹 Run Prometheus & Grafana with Docker**
Add **Prometheus and Grafana** to `docker-compose.yml`:

```yaml
prometheus:
  image: prom/prometheus
  ports:
    - "9090:9090"
  volumes:
    - ./prometheus.yml:/etc/prometheus/prometheus.yml

grafana:
  image: grafana/grafana
  ports:
    - "3000:3000"
```

✅ **Grafana UI is available at** `http://localhost:3000`.

---

### **🔹 Configure Prometheus to Scrape Metrics**
Create a **`prometheus.yml`** file:

```yaml
global:
  scrape_interval: 5s
scrape_configs:
  - job_name: 'order-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['order-service:8081']

  - job_name: 'payment-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['payment-service:8082']

  - job_name: 'inventory-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['inventory-service:8083']
```

✅ **Prometheus now collects metrics from all microservices!**

---

## **📌 Step 4: Visualizing Data**
### **🔹 View Tracing in Zipkin**
Go to `http://localhost:9411`, filter by `order-service`, and check **end-to-end request tracing**.

### **🔹 View Tracing in Jaeger**
Go to `http://localhost:16686`, select a service (e.g., `order-service`), and view **latency analysis**.

### **🔹 View Metrics in Prometheus**
Visit `http://localhost:9090`, search for **Spring Boot metrics**, e.g.:
```plaintext
http_server_requests_seconds_count
```

### **🔹 Create Dashboards in Grafana**
1. Go to **`http://localhost:3000`**, login (`admin/admin`).
2. Add Prometheus as a data source.
3. Import a **Spring Boot monitoring dashboard**.
4. View **CPU, Memory, and API Response Time metrics**.

✅ **Grafana now visualizes your microservices' performance in real time!**

---

## **📌 Final Workflow**
1️⃣ **Order Service receives a request**, generates a **trace ID**, and starts a transaction.  
2️⃣ **Kafka propagates the trace ID** to **Payment Service**, which **logs the trace**.  
3️⃣ **Payment Service emits an event**, which **Inventory Service processes with tracing enabled**.  
4️⃣ **Zipkin/Jaeger track the request flow** across microservices.  
5️⃣ **Prometheus collects metrics**, and **Grafana visualizes performance dashboards**.

✅ **You can now trace transactions, measure API performance, and monitor microservices efficiently!** 🎉  

---

## **📌 Conclusion**
### **🚀 What We Achieved**
✅ **Implemented distributed tracing with Zipkin & Jaeger.**  
✅ **Enabled service-to-service request tracking in Kafka-based microservices.**  
✅ **Integrated Prometheus & Grafana for monitoring performance.**  
✅ **Configured Docker for easy deployment of monitoring tools.**  

🔹 **Next Steps:**  
- Add **Log Aggregation with ELK Stack (Elasticsearch, Logstash, Kibana)**.  
- Implement **alerting with Prometheus AlertManager**.  
- Optimize **trace sampling for production environments**.  

---

# **Log Aggregation & Alerting in Microservices with ELK Stack & Prometheus AlertManager**

## **🚀 Introduction**  
When running microservices in production, debugging failures and monitoring logs efficiently is **crucial**. Since each microservice runs **independently**, logs are scattered across multiple instances, making it **hard to trace errors**.

### **📌 Why Log Aggregation & Alerting?**
✅ **Centralized Logging** – Collect logs from all microservices in one place.  
✅ **Structured Log Storage** – Use **Elasticsearch** to store logs efficiently.  
✅ **Real-time Log Analysis** – View logs in **Kibana** with filtering & search.  
✅ **Automated Alerts** – Configure **Prometheus AlertManager** to notify on errors.  

---

## **📌 Step 1: Setting Up ELK Stack (Elasticsearch, Logstash, Kibana)**
The **ELK Stack** consists of:
- **Elasticsearch** – Stores structured logs.
- **Logstash** – Collects and processes logs.
- **Kibana** – Provides a UI for searching & visualizing logs.

### **🔹 Add Logback Logging in Each Microservice**
To send logs from **Spring Boot microservices** to ELK, update `pom.xml`:

```xml
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>6.6</version>
</dependency>
```

---

### **🔹 Configure Logback to Send Logs to Logstash**
Create `logback-spring.xml` in `src/main/resources/`:

```xml
<configuration>
    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>logstash:5044</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>

    <root level="INFO">
        <appender-ref ref="LOGSTASH" />
    </root>
</configuration>
```
✅ **This sends structured JSON logs to Logstash at port `5044`.**

---

### **🔹 Add ELK Stack to Docker Compose**
Modify `docker-compose.yml`:

```yaml
elasticsearch:
  image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
  container_name: elasticsearch
  environment:
    - discovery.type=single-node
  ports:
    - "9200:9200"

logstash:
  image: docker.elastic.co/logstash/logstash:7.17.0
  container_name: logstash
  ports:
    - "5044:5044"
  volumes:
    - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf

kibana:
  image: docker.elastic.co/kibana/kibana:7.17.0
  container_name: kibana
  ports:
    - "5601:5601"
```

✅ **Elasticsearch (`9200`), Logstash (`5044`), and Kibana (`5601`) are now configured.**

---

### **🔹 Configure Logstash to Ingest Logs into Elasticsearch**
Create a **Logstash configuration file** (`logstash.conf`):

```plaintext
input {
  tcp {
    port => 5044
    codec => json
  }
}

filter {
  mutate {
    add_field => { "service" => "order-service" }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "microservice-logs"
  }
  stdout { codec => rubydebug }
}
```

✅ **Logstash will collect logs from microservices and send them to Elasticsearch.**

---

### **🔹 Running ELK Stack**
```bash
docker-compose up -d
```
✅ **Visit Kibana UI at** `http://localhost:5601`, go to **Discover**, and search for logs!

---

## **📌 Step 2: Configuring Prometheus AlertManager**
Prometheus **collects application metrics**, and **AlertManager sends alerts** for critical events.

### **🔹 Add AlertManager to Docker Compose**
Modify `docker-compose.yml`:

```yaml
alertmanager:
  image: prom/alertmanager
  ports:
    - "9093:9093"
  volumes:
    - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
```
✅ **AlertManager runs on `http://localhost:9093`**.

---

### **🔹 Configure Alerts in Prometheus**
Modify `prometheus.yml`:

```yaml
global:
  scrape_interval: 5s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - "alertmanager:9093"

rule_files:
  - "alert-rules.yml"

scrape_configs:
  - job_name: 'order-service'
    static_configs:
      - targets: ['order-service:8081']
```

---

### **🔹 Define Alert Rules**
Create `alert-rules.yml`:

```yaml
groups:
  - name: High Error Rate
    rules:
      - alert: HighErrorRate
        expr: rate(http_server_requests_seconds_count{status="500"}[5m]) > 10
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected in Order Service"
```
✅ **If more than 10 errors occur per minute, an alert is triggered.**

---

### **🔹 Configure AlertManager to Send Alerts**
Create `alertmanager.yml`:

```yaml
route:
  receiver: "email-alerts"

receivers:
  - name: "email-alerts"
    email_configs:
      - to: "admin@example.com"
        from: "monitoring@example.com"
        smarthost: "smtp.gmail.com:587"
        auth_username: "your-email@gmail.com"
        auth_password: "your-password"
```
✅ **Alerts will now be sent to your email.**

---

## **📌 Step 3: Testing the Setup**
### **🔹 Trigger a High-Error Scenario**
Manually force an error in `OrderService`:

```java
@GetMapping("/force-error")
public ResponseEntity<String> throwError() {
    throw new RuntimeException("Manual error for testing alerts");
}
```

🚀 **Now, hit the endpoint multiple times:**
```bash
curl http://localhost:8081/force-error
```

1️⃣ **Elasticsearch logs the errors.**  
2️⃣ **Kibana visualizes the logs in real-time.**  
3️⃣ **Prometheus detects high error rates.**  
4️⃣ **AlertManager triggers an alert.**  
5️⃣ **Email notification is sent to `admin@example.com`.**  

✅ **Your microservices now have centralized logging & alerting!** 🎉  

---

## **📌 Step 4: Viewing Logs & Alerts**
### **🔹 View Logs in Kibana**
1. Open `http://localhost:5601`
2. Go to **Discover** → Select `microservice-logs`
3. Search for `"ERROR"` logs to debug failures.

---

### **🔹 View Alerts in Prometheus**
1. Open `http://localhost:9090`
2. Go to **Alerts** → Check if **HighErrorRate** alert is triggered.

---

### **🔹 View Alerts in AlertManager**
1. Open `http://localhost:9093`
2. See active alerts under **Silences & Alerts**.

---

## **📌 Final Workflow**
1️⃣ **Microservices send logs to Logstash.**  
2️⃣ **Logstash processes logs & stores them in Elasticsearch.**  
3️⃣ **Kibana visualizes logs with filtering & search.**  
4️⃣ **Prometheus monitors error rates & system metrics.**  
5️⃣ **AlertManager sends alerts via email when errors spike.**  

✅ **You can now monitor microservices, debug issues faster, and receive automated alerts!** 🎉  

---

## **📌 Conclusion**
### **🚀 What We Achieved**
✅ **Set up centralized logging with ELK Stack (Elasticsearch, Logstash, Kibana).**  
✅ **Configured structured logging in Spring Boot microservices.**  
✅ **Implemented real-time alerts with Prometheus & AlertManager.**  
✅ **Sent alerts via email for critical errors.**  

🔹 **Next Steps:**  
- Add **Slack or Discord notifications** for alerts.  
- Implement **Distributed Log Correlation using Trace IDs**.  
- Use **Grafana for real-time log & metric visualization.**  

