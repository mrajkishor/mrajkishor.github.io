### API Gateway â€“ AWS Service Integration with Kinesis Data Streams Example

API Gateway provides seamless integration with various AWS services, enabling developers to build highly efficient and scalable architectures. One of the common use cases involves integrating **Amazon Kinesis Data Streams** and **Kinesis Data Firehose** to collect, process, and store data in real time. This blog delves into how this integration works and provides a step-by-step guide with examples in **Java** and **React**.

---

### Overview of the Architecture

The workflow involves the following components:

1. **Client**: Sends HTTP requests to the API Gateway.
2. **API Gateway**: Acts as a front-end interface for accepting the requests and forwarding them to Kinesis Data Streams.
3. **Kinesis Data Streams**: Processes the data records in real time.
4. **Kinesis Data Firehose**: Buffers the data and delivers it to a storage destination (e.g., Amazon S3).
5. **Amazon S3**: Stores the processed data as `.json` files or other formats.

---

### Step-by-Step Implementation

#### 1. **Setting Up API Gateway**

1. Navigate to the **API Gateway** service in the AWS Management Console.
2. Create a new **REST API**.
3. Add a **POST** method to the resource path (e.g., `/stream`).
4. Set the integration type to **AWS Service**.
   - Service: `Kinesis`
   - Action: `PutRecord`
   - Region: Choose your AWS region.
5. Configure the mapping template to format the data sent by the client into a format suitable for Kinesis Data Streams.

Example Mapping Template (JSON):
```json
{
  "StreamName": "my-data-stream",
  "Data": "$input.body",
  "PartitionKey": "$context.requestId"
}
```

6. Deploy the API to a specific stage (e.g., `prod`).

---

#### 2. **Creating a Kinesis Data Stream**

1. Navigate to the **Kinesis Data Streams** service.
2. Create a new data stream (e.g., `my-data-stream`).
3. Configure the number of shards based on the expected throughput.

---

#### 3. **Setting Up Kinesis Data Firehose**

1. Navigate to the **Kinesis Data Firehose** service.
2. Create a new delivery stream (e.g., `my-firehose-stream`).
3. Set the source as **Kinesis Data Stream** and select the previously created stream (`my-data-stream`).
4. Set the destination as **Amazon S3** and choose a bucket.
5. Configure the transformation, buffering, and compression options as needed.

---

#### 4. **Storing Data in Amazon S3**

1. Create an S3 bucket (e.g., `my-data-bucket`) to store the JSON files.
2. Ensure the bucket has the necessary permissions for Kinesis Data Firehose to write data.

---

### Example: Sending Data from a Java Client

Below is a simple Java example to send HTTP requests to the API Gateway.

```java
import java.io.OutputStream;
import java.net.HttpURLConnection;
import java.net.URL;

public class KinesisDataStreamExample {
    public static void main(String[] args) {
        try {
            // API Gateway Endpoint
            String apiUrl = "https://<your-api-id>.execute-api.<region>.amazonaws.com/prod/stream";

            // Data to send
            String jsonData = "{ \"message\": \"Hello, Kinesis!\" }";

            // Create a connection
            URL url = new URL(apiUrl);
            HttpURLConnection connection = (HttpURLConnection) url.openConnection();

            // Configure the request
            connection.setDoOutput(true);
            connection.setRequestMethod("POST");
            connection.setRequestProperty("Content-Type", "application/json");

            // Send data
            OutputStream os = connection.getOutputStream();
            os.write(jsonData.getBytes());
            os.flush();
            os.close();

            // Get response
            int responseCode = connection.getResponseCode();
            System.out.println("Response Code: " + responseCode);

        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

---

### Example: Sending Data from a React App

Below is an example of how to send data using a React frontend.

```jsx
import React, { useState } from "react";
import axios from "axios";

const KinesisIntegration = () => {
  const [message, setMessage] = useState("");
  const [response, setResponse] = useState("");

  const sendDataToKinesis = async () => {
    const apiUrl = "https://<your-api-id>.execute-api.<region>.amazonaws.com/prod/stream";

    try {
      const res = await axios.post(apiUrl, { message }, {
        headers: {
          "Content-Type": "application/json",
        },
      });
      setResponse(`Data sent successfully: ${res.status}`);
    } catch (error) {
      setResponse(`Error sending data: ${error.message}`);
    }
  };

  return (
    <div style={{ padding: "20px" }}>
      <h2>Send Data to Kinesis</h2>
      <textarea
        placeholder="Enter your message"
        value={message}
        onChange={(e) => setMessage(e.target.value)}
        rows="5"
        cols="40"
      />
      <br />
      <button onClick={sendDataToKinesis} style={{ marginTop: "10px" }}>
        Send
      </button>
      {response && <p>{response}</p>}
    </div>
  );
};

export default KinesisIntegration;
```

---

### Example Data Flow

1. A user sends a JSON payload (`{ "message": "Hello, Kinesis!" }`) from the React app or Java client.
2. API Gateway receives the request, applies the mapping template, and forwards it to Kinesis Data Streams.
3. Kinesis Data Streams processes the record and sends it to Kinesis Data Firehose.
4. Kinesis Data Firehose delivers the processed data to the specified S3 bucket in `.json` format.

---

### Advantages of This Integration

1. **Scalability**:
   - Kinesis Data Streams and Firehose are highly scalable, handling massive volumes of data in real-time.

2. **Serverless Architecture**:
   - API Gateway and Kinesis eliminate the need for server management.

3. **Data Transformation**:
   - Firehose can transform and compress data before storage.

4. **Cost-Effective**:
   - Pay only for the resources used, making it cost-efficient for large-scale applications.

---

### Use Cases

1. **Real-Time Analytics**:
   - Process and analyze streaming data for real-time insights.

2. **Log Ingestion**:
   - Collect logs from various applications and store them in S3 for analysis.

3. **Event-Driven Applications**:
   - Build event-driven workflows by integrating with AWS Lambda and other services.

---

### Conclusion

Integrating **API Gateway**, **Kinesis Data Streams**, **Kinesis Data Firehose**, and **Amazon S3** provides a powerful and scalable solution for collecting, processing, and storing data in real time. With minimal configuration and code, developers can create a robust serverless architecture that handles large volumes of data efficiently. The provided Java and React examples illustrate how to send data to the API Gateway, making it easier to adopt this pattern for your applications.