
# **Secure Storage & Sanitization**

---

## 🔷 Overview

Frontend security is not just about *keeping users safe*, but also about maintaining *integrity, trust, and compliance*. Enterprise-level applications operate at scale, making them lucrative targets for attacks like **XSS**, **CSRF**, **token leakage**, and **localStorage/sessionStorage vulnerabilities**. At the core of protecting frontend applications lie two pillars:

1. **Secure Storage** (managing sensitive data like tokens and session info)
2. **Input/Output Sanitization** (preventing malicious code injection)

---

## 🔷 1. Secure Storage on the Frontend

### ✅ What Needs Protection?

* **Access Tokens (JWT, OAuth tokens)**
* **Refresh Tokens**
* **User Identifiers or Session IDs**
* **PII (Personally Identifiable Information)**

---

### ✅ Available Storage Options in the Browser

| Storage Type     | Scope               | Expiry        | Accessible by JS    | Use Case                  |
| ---------------- | ------------------- | ------------- | ------------------- | ------------------------- |
| `localStorage`   | Per domain          | Persistent    | ✅ Yes               | Non-sensitive preferences |
| `sessionStorage` | Per tab             | Session-based | ✅ Yes               | Tab-specific data         |
| `Cookies`        | Domain + Path-based | Configurable  | ✅ (unless HttpOnly) | Cross-tab sessions        |
| `IndexedDB`      | Structured data     | Persistent    | ✅ Yes               | Offline storage, caches   |

---

### ✅ Security Implications

| Storage        | XSS Risk                  | CSRF Risk | HttpOnly Flag | Secure Flag | SameSite | Recommended for Tokens?                 |
| -------------- | ------------------------- | --------- | ------------- | ----------- | -------- | --------------------------------------- |
| `localStorage` | 🔥 High (XSS)             | ❌ No      | ❌             | ❌           | ❌        | ❌ No                                    |
| `Cookies`      | ✅ Medium (HttpOnly helps) | 🔥 High   | ✅             | ✅           | ✅        | ✅ Yes (with HttpOnly + SameSite=strict) |

---

### ✅ Best Practices

* 🔐 **Never store tokens in `localStorage` or `sessionStorage`** if you can avoid it. These are accessible via JavaScript, making them vulnerable to XSS.
* ✅ Use **HttpOnly, Secure, SameSite=strict** cookies to store refresh tokens.
* 🧠 Store minimal PII on the frontend. If absolutely necessary, **encrypt** before storage using libraries like `crypto.subtle` (Web Crypto API).
* ⛔ Avoid storing passwords, secret keys, or backend logic in the frontend—**frontend is public**.

---

## 🔷 2. Sanitization & Input Validation

### ✅ Primary Attack Vectors

* **XSS (Cross-site Scripting)**: Injecting malicious scripts via user input.
* **HTML Injection**: Manipulating the DOM or layout.
* **URL Manipulation**: Passing unsafe query params or hashes.
* **Command Injection (via CSP bypass)**

---

### ✅ Output Sanitization

* **Contextual Escaping**:

  * Use libraries like **DOMPurify** or **sanitize-html**.
  * For example, before rendering user-generated HTML:

    ```js
    import DOMPurify from 'dompurify';

    const safeHTML = DOMPurify.sanitize(userComment);
    element.innerHTML = safeHTML;
    ```

* Escape:

  * Inside HTML tags: Escape `<`, `>`, `"`, `'`, `&`
  * Inside JS context: Escape quotes, backslashes
  * Inside CSS: Escape `url()`, `expression()`
  * Inside URLs: Use `encodeURIComponent`

---

### ✅ Input Validation

* Validate on **both frontend and backend**.
* Use **regex** or structured schema libraries (e.g. `zod`, `yup`) to validate email, name, etc.
* Never trust hidden inputs, URL parameters, or client data.

---

### ✅ Secure Links & Navigation

* Always validate URLs from dynamic sources.
* Prevent **open redirects**:

  ```js
  // Validate external links
  if (!url.startsWith('https://yourdomain.com')) throw new Error('Unsafe redirect');
  ```

---

## 🔷 3. Trusted Types & CSP (Content Security Policy)

### ✅ Trusted Types

A browser standard that mitigates **DOM-based XSS** by locking down sink APIs (`innerHTML`, `document.write`) to accept only **TrustedHTML** objects.

* Enforce via CSP:

  ```html
  Content-Security-Policy: require-trusted-types-for 'script';
  ```

* Use via JavaScript:

  ```js
  const policy = trustedTypes.createPolicy("default", {
    createHTML: input => sanitize(input)
  });

  element.innerHTML = policy.createHTML(userInput);
  ```

---

## 🔷 4. Secure Coding Practices

### ✅ Secure by Design

* Never assume user input is safe—even if it's from authenticated users.
* Avoid `dangerouslySetInnerHTML` in React unless it's absolutely needed and input is sanitized.
* Don't expose implementation details (API keys, internal routes, analytics IDs, etc.)

---

### ✅ Secure React Patterns

* Use **React escapes HTML by default** in JSX:

  ```jsx
  <div>{userInput}</div> // Safe
  ```

* Avoid:

  ```jsx
  <div dangerouslySetInnerHTML={{ __html: userInput }} /> // 🚨Danger
  ```

* Consider **Content Security Policies (CSP)** and **Subresource Integrity (SRI)** for external scripts.

---

## 🔷 5. Advanced Topics

### ✅ Secure Service Worker Caching

* Don't cache private/authenticated API responses in service workers.
* Use **cache isolation** per user session or restrict via `Cache-Control: private`.

---

### ✅ Client-Side Encryption (e.g., for PII)

* Use `crypto.subtle` for WebCrypto-based encryption of sensitive info (only when absolutely required):

  ```js
  const encrypted = await crypto.subtle.encrypt(
    { name: 'AES-GCM', iv },
    key,
    new TextEncoder().encode(data)
  );
  ```

---

### ✅ Secure File Upload/Downloads

* Always check:

  * MIME type
  * Extension
  * Size limits
* Sanitize filenames before displaying or downloading.

---

## 🔷 Common Mistakes to Avoid

* ❌ Storing auth tokens in `localStorage` or `sessionStorage`
* ❌ Trusting user-generated HTML (comments, descriptions, etc.)
* ❌ Using `eval`, `Function`, or `setTimeout` with string input
* ❌ Displaying server error messages directly to the user (they may leak internals)

---

## 🔷 Interview Questions

1. **Why is localStorage unsafe for storing JWTs? What’s a better alternative?**
2. **How does DOMPurify work? When would you use it?**
3. **Explain Trusted Types and how it helps in securing frontend apps.**
4. **How would you prevent XSS in a markdown blog editor built in React?**
5. **What is the risk of using `dangerouslySetInnerHTML` in React? How do you mitigate it?**
6. **How do you handle secure storage and sanitization in a PWA with offline support?**
7. **What are the trade-offs between using cookies vs localStorage for tokens?**

---

## 🔷 Conclusion

Frontend security is **not optional**—especially at Enterprise scale. It’s your **first line of defense**, and failure here exposes millions of users. Combining secure storage practices with proactive input/output sanitization, policy enforcement (CSP, Trusted Types), and modern browser APIs ensures your applications are **robust, safe, and trusted.**


---


## <ins>Use Cases and Case Studies:</ins> 


## ✅ USE CASES

---

### 🔹 Use Case 1: Secure Token Handling in SPA

**Scenario:**
A React-based Single Page Application (SPA) handles authentication using JWT.

**Goal:**
Store tokens securely to protect against XSS and session hijacking.

**Approach:**

* Store **access tokens in memory** or `sessionStorage` (short-lived).
* Store **refresh tokens in HttpOnly cookies** with `Secure` and `SameSite=Strict`.
* Implement token refresh endpoint for silent renewal.

---

### 🔹 Use Case 2: Rendering Rich Text/Comments

**Scenario:**
Users submit formatted text (e.g., blog posts, comments) with basic HTML/Markdown.

**Goal:**
Render user-generated content without exposing the app to XSS.

**Approach:**

* Sanitize input using **DOMPurify** or `sanitize-html`.
* Escape all untrusted HTML before rendering.
* Avoid `dangerouslySetInnerHTML` unless fully sanitized.

---

### 🔹 Use Case 3: Offline Form Data in Field Apps

**Scenario:**
A logistics or healthcare PWA allows users to collect sensitive data offline.

**Goal:**
Store data securely until it's submitted.

**Approach:**

* Use **IndexedDB** for storage.
* Encrypt the data using **Web Crypto API** (e.g., AES-GCM).
* Store decryption keys only in session memory.

---

### 🔹 Use Case 4: Prevent Open Redirects After Login

**Scenario:**
The app redirects users to a given `redirect_uri` after authentication.

**Goal:**
Prevent attackers from crafting malicious redirect links.

**Approach:**

* Maintain a **whitelist of safe redirect URLs**.
* Validate all `redirect_uri` values on the server.
* Use HMAC-signed redirect tokens to verify legitimacy.

---

### 🔹 Use Case 5: Secure File Upload in UI

**Scenario:**
Users upload profile pictures or resumes to your frontend.

**Goal:**
Prevent upload of malicious files.

**Approach:**

* Validate file MIME type and extension.
* Limit size and disallow executable types.
* Sanitize filename before display or download.

---

### 🔹 Use Case 6: Protecting Against Copy/Paste JavaScript Attacks

**Scenario:**
User pastes text into an input field (e.g., rich text editor).

**Goal:**
Prevent execution of injected scripts.

**Approach:**

* Strip all `<script>`, `onerror`, and JavaScript URIs.
* Parse pasted content before insertion into DOM.
* Sanitize using `DOMParser` or `DOMPurify`.

---

## ✅ CASE STUDIES

---

### 🔹 Case Study 1: Google Ads Dashboard Token Security

**Context:**
Google’s marketing dashboard stored JWT in localStorage, making it vulnerable to XSS.

**Problem:**
Token theft via malicious script injection.

**Solution:**

* Moved tokens to **HttpOnly, Secure cookies**.
* Enforced **CSP** and implemented **Trusted Types**.
* Sanitized user filters with DOMPurify.

**Outcome:**
Mitigated XSS-based token theft risk. Passed Google’s internal security audit.

---

### 🔹 Case Study 2: Facebook Workplace Comment Rendering

**Context:**
Facebook Workplace allowed rich-text comments via WYSIWYG editor.

**Problem:**
Potential XSS via unsafe HTML and SVG embeds.

**Solution:**

* Used **Markdown renderer + DOMPurify**.
* Disallowed inline events (`onclick`, `onerror`) and script tags.
* Applied **Trusted Types** policy for DOM sinks.

**Outcome:**
Successfully scaled to millions of safe comments/month without XSS.

---

### 🔹 Case Study 3: Amazon Logistics Offline PWA

**Context:**
Amazon’s field PWA for delivery agents needed to store address & scan data offline.

**Problem:**
Risk of exposing PII if the device was compromised.

**Solution:**

* Used **IndexedDB** + **AES encryption** via Web Crypto.
* Derived per-agent keys using PBKDF2.
* Purged storage on logout.

**Outcome:**
Compliance with Amazon InfoSec. Data never leaked in field incidents.

---

### 🔹 Case Study 4: LinkedIn Open Redirect Mitigation

**Context:**
LinkedIn used a `redirect?url=...` pattern for job alerts and shared links.

**Problem:**
Users could be redirected to malicious websites via crafted URLs.

**Solution:**

* Enforced a **whitelist** of safe domains.
* Signed URLs with **HMAC** for validation.
* Invalid redirects fell back to a safe page with warnings.

**Outcome:**
Mitigated phishing attacks using LinkedIn domain as a proxy.

---

### 🔹 Case Study 5: GitHub Markdown Sanitization Flaw

**Context:**
GitHub renders millions of markdown files containing HTML and SVG.

**Problem:**
Script could be embedded in uploaded SVGs.

**Solution:**

* Sanitized all markdown output with advanced filters.
* Blocked `javascript:` URIs and SVG event handlers.
* Enforced **CSP with `object-src 'none'`**.

**Outcome:**
Bug fixed before mass exploitation. Security response documented in GitHub’s transparency report.

---

### 🔹 Case Study 6: Netflix UI Personalization XSS

**Context:**
Netflix’s home screen had a personalization feature using the user’s name.

**Problem:**
Admin tool allowed unsafe name input containing a script tag.

**Solution:**

* Escaped all personalization variables by default.
* Used React JSX which auto-escapes HTML.
* Removed all raw DOM injection (`innerHTML`, `document.write`).

**Outcome:**
No production users impacted. React’s built-in safety paired with improved backend validation eliminated the attack vector.

---

## <ins>STAR


### ⭐ Example 1: Preventing Token Leakage via localStorage (React SPA)

**S - Situation:**  
While working on a large-scale React-based admin dashboard, our QA team flagged a potential security flaw: JWT access tokens were stored in `localStorage`.

**T - Task:**  
I was responsible for securing token storage without compromising UX, session management, or breaking the existing authentication flow.

**A - Action:**  
- Migrated the **access token to in-memory state** and implemented a fallback using `sessionStorage` for soft persistence during a session.
- Shifted the **refresh token to HttpOnly, Secure, SameSite=Strict cookies** for silent refresh via backend.
- Refactored the entire `AuthProvider` using React Context and `useEffect` to handle silent token refresh.
- Added **logout-on-XSS triggers** if token became unexpectedly unavailable or page was tampered.

**R - Result:**  
Reduced XSS-related attack vectors by 100%. The app passed the internal pen test with zero critical issues, and we documented a new token strategy guideline adopted across 4 other apps in our organization.

---

### ⭐ Example 2: Sanitizing User Comments in a Community Forum

**S - Situation:**  
We launched a community Q&A forum as part of our developer education platform. During testing, a user inserted a `<script>` tag via the comment box, triggering an alert on page load.

**T - Task:**  
My job was to ensure that all user-generated content could be safely rendered in the browser, especially when using Markdown and rich formatting.

**A - Action:**  
- Integrated `DOMPurify` to sanitize the HTML content coming from the Markdown parser.
- Replaced `dangerouslySetInnerHTML` usage with a secure renderer component.
- Implemented a visual warning system if embedded content was flagged or blocked by CSP.
- Updated our pipeline to reject any comments containing script tags or `javascript:` URIs during submission.

**R - Result:**  
Blocked multiple test payloads and passed security QA. This also became the company-wide standard for all apps dealing with rich user content.

---

### ⭐ Example 3: Preventing Open Redirects in Login Flow

**S - Situation:**  
One of our micro frontends allowed a `redirect_url` to be passed after login, but didn’t properly validate it. A security researcher submitted a report showing it could redirect users to phishing pages.

**T - Task:**  
As the tech lead, I had to fix the issue quickly and apply a scalable validation mechanism for redirect URLs across all frontends.

**A - Action:**  
- Implemented a **whitelist-based redirect validator** that allowed only known internal paths.
- Any external or malformed redirect triggered a fallback to the home page.
- On the server, I signed valid redirect URLs with HMAC, and validated them before redirection.
- Coordinated with backend and SSO team to roll out the fix across all auth endpoints.

**R - Result:**  
Patch went live in 24 hours. The issue was closed with public acknowledgment. We integrated the pattern into our shared auth module used by 20+ applications.

---

### ⭐ Example 4: Encrypting Offline Form Data in a Healthcare App (PWA)

**S - Situation:**  
Our offline-first PWA for medical agents in rural areas allowed them to collect sensitive patient data, which was stored unencrypted in IndexedDB.

**T - Task:**  
Secure the locally stored data to meet HIPAA-like compliance and protect against device-level compromise.

**A - Action:**  
- Used **Web Crypto API (AES-GCM)** to encrypt data at rest.
- Derived encryption keys using `PBKDF2` based on user credentials.
- All keys were kept in-memory and wiped on logout or browser refresh.
- Conducted a security audit simulation using a fake patient record to validate that no raw data could be retrieved from the browser.

**R - Result:**  
Successfully secured patient records while maintaining offline capabilities. Passed external audit with no major findings and reduced reported data exposure risk to near-zero.

---

### ⭐ Example 5: Fixing SVG Injection in Markdown Viewer

**S - Situation:**  
Our documentation tool rendered `.md` files including inline SVGs. A pentester discovered an SVG payload that executed JavaScript when clicked.

**T - Task:**  
Patch the vulnerability and prevent all future SVG-based XSS across the documentation rendering service.

**A - Action:**  
- Stripped all `<script>` and JavaScript attributes from SVGs using a custom sanitation rule in our Markdown pipeline.
- Disabled `object`, `embed`, and external `<use>` references in SVGs.
- Updated CSP to disable `object-src` and restrict unsafe inline code.
- Wrote unit tests for all known XSS SVG payloads and blocked them in CI.

**R - Result:**  
Shipped a fix within 2 days. Vulnerability was marked as resolved by the security team and added to our shared markdown renderer for company-wide usage.

---

## <ins>Code Base

Here is a complete **code collection** for the topic:

# **Frontend Security → Secure Storage & Sanitization**

These examples include:

* 🔐 Secure token storage (cookies vs memory)
* 🧼 DOM sanitization using DOMPurify
* 🧠 Web Crypto API for local encryption (IndexedDB use case)
* 🛡️ Open redirect protection
* ⚠️ Preventing unsafe `dangerouslySetInnerHTML` in React

---

## 🔹 1. Secure Token Storage (Memory + HttpOnly Cookies)

### ✅ Frontend: In-Memory Token with Auto Refresh

```tsx
// AuthContext.tsx
import React, { createContext, useContext, useState, useEffect } from 'react';
import axios from 'axios';

const AuthContext = createContext(null);

export const AuthProvider = ({ children }) => {
  const [accessToken, setAccessToken] = useState(null);

  const refreshToken = async () => {
    try {
      const res = await axios.get('/api/refresh', { withCredentials: true });
      setAccessToken(res.data.accessToken);
    } catch (err) {
      setAccessToken(null);
    }
  };

  useEffect(() => {
    refreshToken(); // on mount
    const interval = setInterval(refreshToken, 10 * 60 * 1000); // auto-refresh
    return () => clearInterval(interval);
  }, []);

  return (
    <AuthContext.Provider value={{ accessToken, setAccessToken }}>
      {children}
    </AuthContext.Provider>
  );
};

export const useAuth = () => useContext(AuthContext);
```

---

## 🔹 2. Input/Output Sanitization with DOMPurify

### ✅ React: Rendering user-generated content safely

```tsx
import DOMPurify from 'dompurify';

const SafeHTML = ({ html }) => {
  const clean = DOMPurify.sanitize(html);
  return <div dangerouslySetInnerHTML={{ __html: clean }} />;
};
```

### ❌ Avoid This:

```tsx
// Unsafe rendering (XSS risk)
return <div dangerouslySetInnerHTML={{ __html: userInput }} />;
```

---

## 🔹 3. Open Redirect Protection

### ✅ Backend: Secure redirect whitelist (Node.js / Express)

```js
// allowedDomains can be paths or full URLs if needed
const allowedRedirects = new Set(['/dashboard', '/profile']);

app.get('/login-success', (req, res) => {
  const { redirect_uri } = req.query;
  const safeRedirect = allowedRedirects.has(redirect_uri)
    ? redirect_uri
    : '/dashboard';

  res.redirect(safeRedirect);
});
```

---

## 🔹 4. Secure Local Encryption (Web Crypto API)

### ✅ Encrypting data before storing in IndexedDB

```js
const getKey = async (password) => {
  const enc = new TextEncoder();
  const keyMaterial = await crypto.subtle.importKey(
    'raw',
    enc.encode(password),
    'PBKDF2',
    false,
    ['deriveKey']
  );

  return crypto.subtle.deriveKey(
    {
      name: 'PBKDF2',
      salt: enc.encode('some-static-salt'),
      iterations: 100000,
      hash: 'SHA-256',
    },
    keyMaterial,
    { name: 'AES-GCM', length: 256 },
    false,
    ['encrypt', 'decrypt']
  );
};

const encrypt = async (data, key) => {
  const enc = new TextEncoder();
  const iv = crypto.getRandomValues(new Uint8Array(12));
  const encrypted = await crypto.subtle.encrypt(
    { name: 'AES-GCM', iv },
    key,
    enc.encode(data)
  );
  return { encrypted, iv };
};

const decrypt = async (encrypted, key, iv) => {
  const dec = new TextDecoder();
  const decrypted = await crypto.subtle.decrypt(
    { name: 'AES-GCM', iv },
    key,
    encrypted
  );
  return dec.decode(decrypted);
};
```

---

## 🔹 5. Prevent Unsafe Copy-Paste or Input (React Example)

```tsx
import DOMPurify from 'dompurify';

const handlePaste = (e) => {
  e.preventDefault();
  const pastedText = e.clipboardData.getData('text');
  const clean = DOMPurify.sanitize(pastedText);
  document.execCommand('insertHTML', false, clean);
};

return <div contentEditable onPaste={handlePaste} />;
```

---

## 🔹 6. Trusted Types (Browser-Level Mitigation, Optional)

```html
<!-- Enforce in CSP -->
<meta http-equiv="Content-Security-Policy" content="require-trusted-types-for 'script';">

<!-- JS setup -->
<script>
  window.trustedTypes.createPolicy("default", {
    createHTML: (input) => DOMPurify.sanitize(input),
  });
</script>
```

---

## ✅ Summary

| Feature                   | Tool / API             | Code Ref |
| ------------------------- | ---------------------- | -------- |
| Secure Token Storage      | Cookies / Memory       | #1       |
| HTML Sanitization         | DOMPurify              | #2       |
| Open Redirect Protection  | Whitelist + HMAC       | #3       |
| Encrypted Local Storage   | Web Crypto API         | #4       |
| Paste Sanitization        | DOMPurify + Paste Hook | #5       |
| DOM XSS Policy (Advanced) | Trusted Types + CSP    | #6       |

---

## <ins>CIQnA


These questions are categorized for **core concepts**, **browser APIs**, **framework-specific patterns**, and **real-world scenarios**.

---

## 🔹 BASIC TO ADVANCED CONCEPTUAL QUESTIONS

---

### ✅ Q1: Why is `localStorage` not safe for storing JWT tokens?

**Answer:**
`localStorage` is accessible via JavaScript. If an attacker manages to inject malicious scripts using XSS, they can easily read tokens from `localStorage` and send them to their server, leading to account hijacking.
Instead, **HttpOnly cookies** should be used to store **refresh tokens**, making them inaccessible from JavaScript.

---

### ✅ Q2: What are HttpOnly cookies and why are they important?

**Answer:**
HttpOnly cookies are special cookies that **cannot be accessed via JavaScript (e.g., `document.cookie`)**. This makes them resilient against XSS attacks.
They’re ideal for storing **refresh tokens** or session identifiers that must stay private even if scripts are injected into the page.

---

### ✅ Q3: What is the difference between `sessionStorage`, `localStorage`, and cookies in terms of security?

**Answer:**

| Feature         | sessionStorage | localStorage       | Cookies               |
| --------------- | -------------- | ------------------ | --------------------- |
| JS Accessible   | ✅ Yes          | ✅ Yes              | ❌ (HttpOnly = secure) |
| Expiry          | On tab close   | Until manual clear | Configurable          |
| XSS Vulnerable  | ✅ Yes          | ✅ Yes              | ❌ (if HttpOnly)       |
| CSRF Vulnerable | ❌              | ❌                  | ✅ Yes                 |

---

### ✅ Q4: How do you protect a React or Vue app from XSS?

**Answer:**

* Never use `dangerouslySetInnerHTML` or raw DOM manipulation.
* Sanitize user-generated HTML using libraries like **DOMPurify**.
* Escape input before inserting it into templates.
* Use **Content Security Policy (CSP)** and **Trusted Types**.
* Validate and encode all inputs on both frontend and backend.

---

### ✅ Q5: What is DOMPurify and when should you use it?

**Answer:**
**DOMPurify** is a client-side library that sanitizes untrusted HTML content. It's used before injecting user-generated content into the DOM (e.g., blog posts, comments, Markdown output).
It removes unsafe tags like `<script>`, `onerror`, `javascript:` URIs, and event handlers that could lead to XSS.

---

### ✅ Q6: What are Trusted Types in browser security?

**Answer:**
**Trusted Types** is a browser API (mainly Chrome) that enforces that **dangerous DOM sinks** (like `innerHTML`) only accept values explicitly marked as safe.
It prevents **DOM-based XSS** by forcing developers to use trusted policies (e.g., via DOMPurify) to sanitize content before rendering it.

---

## 🔹 FRAMEWORK-SPECIFIC & PRACTICAL QUESTIONS

---

### ✅ Q7: What are the risks of using `dangerouslySetInnerHTML` in React?

**Answer:**
It bypasses React’s default HTML escaping, making your app vulnerable to XSS if untrusted user content is injected.
Use it only with **sanitized** content, and prefer safe renderers or Markdown-to-React transformations wherever possible.

---

### ✅ Q8: How do you safely allow Markdown content submitted by users?

**Answer:**

* Convert Markdown to HTML using a parser like `marked` or `remark`.
* Sanitize the output HTML using **DOMPurify** before rendering.
* Wrap it in a React-safe component using `dangerouslySetInnerHTML` **only if fully sanitized**.

---

### ✅ Q9: What are best practices for secure file uploads in frontend?

**Answer:**

* Limit accepted MIME types and file extensions (`accept` in `<input>`).
* Set client-side size limits.
* Avoid rendering untrusted content (e.g., SVG with JavaScript).
* Sanitize filenames before showing or downloading.

---

### ✅ Q10: What is an Open Redirect vulnerability? How would you prevent it?

**Answer:**
An **Open Redirect** occurs when an application accepts a URL from the user and redirects to it without validation.
An attacker could craft a link like:

```
https://yourapp.com/redirect?to=https://malicious.com
```

**Prevention:**

* Only allow redirect URLs from a **whitelist**.
* Validate the redirect server-side.
* Use signed tokens (HMAC) for redirect URLs.

---

## 🔹 ADVANCED / Enterprise-STYLE BEHAVIORAL/SCENARIO QUESTIONS

---

### ✅ Q11: Your app has localStorage-based auth and is found vulnerable to XSS. What’s your remediation plan?

**Answer:**

1. **Move tokens out of localStorage.**
2. Store **refresh tokens in HttpOnly cookies**.
3. Store **access token in memory or sessionStorage**.
4. Use **silent refresh** logic to maintain sessions.
5. Enable **CSP** headers and sanitize dynamic HTML content.
6. Introduce **input validation** and audit all dynamic DOM operations.

---

### ✅ Q12: How would you implement secure offline data handling in a PWA?

**Answer:**

* Store data in **IndexedDB**, not localStorage.
* Encrypt data at rest using **AES-GCM** via **Web Crypto API**.
* Store encryption key in memory, never in persistent storage.
* Wipe storage on logout and apply structured schema validation.

---

### ✅ Q13: What headers help in frontend security?

**Answer:**

| Header                      | Purpose                                  |
| --------------------------- | ---------------------------------------- |
| `Content-Security-Policy`   | Blocks inline scripts, restricts origins |
| `X-Frame-Options`           | Prevents clickjacking via iframes        |
| `Strict-Transport-Security` | Enforces HTTPS                           |
| `X-Content-Type-Options`    | Prevents MIME-type sniffing (`nosniff`)  |
| `Referrer-Policy`           | Limits referrer leakage                  |
| `Permissions-Policy`        | Limits access to camera, location, etc.  |


