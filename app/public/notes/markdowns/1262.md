

# üî∑ Chapter 3.4: Recognition of Tokens

### 1. Goal

* Implement a **mechanical procedure** that converts regex/token specifications ‚Üí an actual **lexer** that scans input and produces tokens.
* Core idea:

  * **Regex** define token patterns.
  * **Finite automata (DFA/NFA)** are used to recognize them.
  * The **lexer** runs these automata over the input.

---

### 2. Transition Diagrams (3.4.1)

* DFA/NFA can be represented as **transition diagrams**:

  * **States** = circles.
  * **Edges** = labeled by character classes (input symbols).
  * **Start state** = entry point.
  * **Accepting state** = when a valid token is recognized.
* Example: DFA for identifiers (`letter (letter|digit)*`):

  * State 0: on `letter` ‚Üí go to State 1.
  * State 1: on `letter/digit` ‚Üí stay in State 1.
  * Accepting state = 1.
* Each token pattern has its own DFA; combined DFA handles multiple token types.

---

### 3. Recognition of Reserved Words and Identifiers (3.4.2)

* Problem: Reserved words (e.g., `while`) match the same pattern as identifiers (`letter (letter|digit)*`).
* Solution:

  1. Use regex for identifiers.
  2. When an identifier is recognized, **check symbol table / keyword table**.

     * If found ‚Üí classify as keyword.
     * Else ‚Üí classify as identifier.
* Example: Input `"while"` ‚Üí recognized as `id` first ‚Üí keyword lookup ‚Üí token `(keyword, while)`.

---

### 4. Completing the Running Example (3.4.3)

* Consider input string `"position = initial + rate * 60"`.
* DFA runs across input, tokenizing:

  * `position` ‚Üí `id`
  * `=` ‚Üí assignment operator
  * `initial` ‚Üí `id`
  * `+` ‚Üí plus operator
  * `rate` ‚Üí `id`
  * `*` ‚Üí multiplication operator
  * `60` ‚Üí number
* The **lexeme boundaries** are decided by longest valid match.

---

### 5. Architecture of a DFA-based Lexer (3.4.4)

* Real-world lexer design:

  * **Input Buffer**: Handles characters efficiently (with sentinels).
  * **DFA Engine**: Runs transition diagrams to recognize tokens.
  * **Token Generator**: Produces `(token-name, attribute)` pairs.
  * **Symbol Table**: Stores identifiers with their attributes.
* Process:

  1. Start at `lexemeBegin`.
  2. Move `forward` until DFA fails.
  3. Longest prefix recognized = token.
  4. Return token + attribute to parser.

---

### 6. Implementation Issues

* **Longest Match Rule**: Lexer always chooses the longest valid lexeme.
* **Priority Rule**: If multiple tokens possible, priority order decides (keywords > identifiers, etc.).
* **Lookahead**: Needed to disambiguate tokens (e.g., `=` vs `==`).

---

# ‚úÖ GATE Pointers

* **Transition diagram interpretation**: PYQs often show DFA and ask which string is accepted.
* **Longest match vs priority rule**: Very common theory question.
* **Reserved word recognition**: Classic MCQ (‚Äúwhy keywords don‚Äôt need separate regex?‚Äù).
* **Architecture of a lexer**: 1-mark conceptual.
* **Regex ‚Üí NFA ‚Üí DFA** conversion: Often tested in TOC + Compiler combined questions.


