
# ðŸ”· Chapter 3.1: The Role of the Lexical Analyzer

### 1. Purpose of the Lexical Analyzer

* The **lexical analyzer (scanner)** is the first phase of the compiler.
* It reads the **raw source code** (character stream) and groups characters into **lexemes**, which are converted into **tokens**.
* Example: Input

  ```c
  int count = 10;
  ```

  Tokens: `(keyword, "int")`, `(id, "count")`, `(=)`, `(num, 10)`, `(;)`.

---

### 2. Advantages of Separating Lexical Analysis

1. **Simplification of the Parser**

   * Parser deals only with tokens, not raw characters â†’ grammar becomes simpler.
2. **Efficiency**

   * Specialized buffering techniques (double buffering, sentinels) make scanning fast.
3. **Portability**

   * Device-dependent I/O is isolated in the lexer â†’ the rest of the compiler is device-independent.

---

### 3. Tokens, Patterns, and Lexemes

* **Token**: A pair `(token-name, attribute-value)`.

  * `token-name`: Abstract symbol (e.g., `id`, `num`, `if`).
  * `attribute-value`: Extra info (e.g., pointer to symbol table entry, actual numeric value).
* **Pattern**: Rule describing what lexemes of a token look like.

  * Example: Identifiers â†’ `letter (letter | digit)*`.
* **Lexeme**: Actual string from source that matches a token pattern.

  * Example: `"score"` is a lexeme for token `id`.

ðŸ‘‰ Example table:

| Token     | Pattern                           | Sample Lexemes      |
| --------- | --------------------------------- | ------------------- |
| `if`      | Characters `i f`                  | `if`                |
| `id`      | Letter followed by letters/digits | `x`, `count`, `D2`  |
| `num`     | Any numeric constant              | `3`, `0`, `6.02e23` |
| `literal` | String in quotes                  | `"hello"`, `"core"` |

---

### 4. Attributes for Tokens

* Tokens often carry **attributes** needed in later phases:

  * **Numbers** â†’ actual integer/float value.
  * **Identifiers** â†’ pointer to symbol table entry (where type, scope, etc., are stored).
  * **Keywords** â†’ token name itself (no attributes needed).

Example:

* Lexeme `"count"` â†’ token `(id, pointer to symbol table entry for count)`.

---

### 5. Lexical Errors

* Typical errors:

  * Misspelled keywords (`flaot` instead of `float`).
  * Invalid characters (`@` in C code).
* Recovery strategies:

  * **Skipping**: Ignore illegal character.
  * **Insertion**: Add missing character.
  * **Deletion**: Remove extra character.
  * **Substitution**: Replace incorrect character with likely correct one.
* Goal: Recover quickly & continue scanning.

---

### 6. Tricky Problems in Token Recognition

* Example from **Fortran**:

  ```
  DO 5 I = 1,25
  ```

  Could be:

  * `DO` loop statement, or
  * `DO5I = 1.25` (assignment with floating number).
* Lexical analysis must sometimes rely on **lookahead** to distinguish tokens.

---

# âœ… GATE Pointers

* **Token vs Lexeme vs Pattern**: Very frequently asked.
* **Role separation (lexer vs parser)**: Classic 1â€“2 mark theory.
* **Attributes** (symbol table pointer, values) often appear in PYQs.
* **Error handling**: Strategies like skipping/insertion/deletion.
* **Tricky recognition**: Lookahead necessity (exam trap with Fortran DO loop).

