
### **Indexes, Unique Constraints, and Auto Increment**

---

## **Concept**

### **Indexes in MySQL**

An **index** is a data structure (commonly a B-Tree or a variant) that MySQL uses to speed up data retrieval. Instead of scanning every row, MySQL uses indexes to directly locate rows that match a condition.

**Types of Indexes in MySQL:**

1. **Primary Key Index** –

   * Uniquely identifies each row.
   * Automatically created when you define a `PRIMARY KEY`.
   * **Clustered index** in InnoDB → data is physically ordered by the primary key.

2. **Unique Index** –

   * Ensures values in a column (or set of columns) are unique.
   * Allows one `NULL` per column in MySQL unless `NOT NULL` is specified.
   * Example:

     ```sql
     CREATE UNIQUE INDEX idx_email ON users(email);
     ```

3. **Regular (Non-Unique) Index** –

   * Speeds up lookups but does not enforce uniqueness.

4. **Composite Index** –

   * Index across multiple columns.
   * Order matters for usage (`INDEX(col1, col2)` works for `(col1)` and `(col1, col2)` lookups but not `(col2)` alone unless index is covering).

5. **Full-Text Index** –

   * For natural language searching in text columns.
   * Uses an inverted index rather than B-Tree.

6. **Spatial Index** –

   * Optimized for geometric data types (GIS).

---

### **Unique Constraints**

A **unique constraint** ensures that all values in a column (or combination of columns) are distinct.

* **Difference from Primary Key**:

  * A table can have **only one** primary key but **multiple** unique constraints.
  * Primary key cannot be `NULL`, but unique constraint allows `NULL` (unless explicitly restricted).

* Example:

  ```sql
  CREATE TABLE employees (
      emp_id INT PRIMARY KEY,
      email VARCHAR(255) UNIQUE,
      dept_id INT,
      UNIQUE(dept_id, email)
  );
  ```

* **Performance Impact**:

  * A unique constraint automatically creates a unique index.
  * Inserts/updates require additional check → slightly slower writes.

---

### **AUTO\_INCREMENT**

* Automatically generates sequential integer values when inserting rows.

* **Rules**:

  * Only one `AUTO_INCREMENT` column per table.
  * Must be indexed (typically `PRIMARY KEY`).
  * Resets if you `TRUNCATE` the table.

* Example:

  ```sql
  CREATE TABLE orders (
      order_id BIGINT AUTO_INCREMENT PRIMARY KEY,
      customer_id INT,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  );
  ```

* **Concurrency in AUTO\_INCREMENT**:

  * InnoDB uses an **AUTO\_INCREMENT lock** to prevent gaps, but gaps can still occur if a transaction rolls back.
  * For high insert throughput, `innodb_autoinc_lock_mode` can be tuned:

    * `0` (Traditional) – safe, serialized inserts.
    * `1` (Consecutive) – default, minimal gaps.
    * `2` (Interleaved) – fastest for bulk inserts, but gaps more likely.

---

## **Internal Mechanics**

### **Index Storage**

* In **InnoDB**, primary key is **clustered**:

  * Data rows stored in leaf nodes of the primary key index.
  * Secondary indexes store **primary key values** in leaves instead of full row addresses → means every secondary index lookup requires a primary key lookup.
* In **MyISAM**, indexes store **pointers** to data file locations.

---

### **How Indexes Affect Queries**

* Reduces search space via **index range scans**.
* Allows **covering indexes** where all required columns are in the index → avoids extra table lookups.
* Increases **write cost** because each insert/update must maintain indexes.

---

## **Best Practices**

1. **Index selectively** – Indexes speed reads but slow writes and take disk space.
2. **Use composite indexes wisely** – Order by most selective column first.
3. **Avoid redundant indexes** – MySQL won’t benefit from two identical indexes.
4. **Enforce business rules with unique constraints** rather than application logic alone.
5. **Consider UUID vs AUTO\_INCREMENT**:

   * AUTO\_INCREMENT → sequential, better for clustered indexes but can be a single-point contention in distributed inserts.
   * UUID → avoids collisions across distributed nodes but has larger index size.

---

## **Pitfalls & Edge Cases**

* AUTO\_INCREMENT gaps on transaction rollback can break expectations if sequence continuity matters.
* Unique constraint checks may cause locking issues under high concurrency.
* Too many indexes can cause **query optimizer confusion** → MySQL might pick a suboptimal index.
* In MySQL, **prefix indexes** (`INDEX(col(10))`) save space but can cause false positives requiring extra comparisons.

---

## <ins> Case studies:



### **Case Study 1 – Optimizing High-Traffic Search Queries**

**Background**
A large e-commerce platform with millions of products noticed slow search results for category and brand filters.

**Problem**
The product listing query was filtering by `category_id` and `brand_id` but had no composite index. This caused frequent full table scans, especially during sales events.

**Multiple Team Efforts**

* **DBA** analyzed slow query logs and identified missing indexes.
* **Backend team** tested query rewrites to confirm index usage.
* **Infra team** stress-tested the change under simulated traffic.

**Code or Architectural Decisions**

```sql
CREATE INDEX idx_category_brand ON products(category_id, brand_id);
```

* Added a **composite index** to match the filter pattern.
* Rewrote the query to match index order for better selectivity.

**Broader Business Impact**

* Reduced search query execution time from **1.8 seconds to 35 ms** under peak load.
* Enabled higher concurrency without scaling database hardware.

**Lessons Learned / Future Steps**

* Always align composite index order with most selective filters.
* Monitor slow query log continuously to detect new index needs.

---

### **Case Study 2 – Preventing Duplicate Registrations**

**Background**
A SaaS platform had multiple customers reporting duplicate accounts being created for the same email address.

**Problem**
The application logic checked for email existence before inserting, but concurrent requests bypassed the check, causing duplicates.

**Multiple Team Efforts**

* **Backend engineers** confirmed the bug was due to race conditions.
* **DBA** proposed enforcing uniqueness at the schema level.

**Code or Architectural Decisions**

```sql
ALTER TABLE users ADD CONSTRAINT uc_email UNIQUE (email);
```

* Added a **unique constraint** on `email` to guarantee database-level enforcement.

**Broader Business Impact**

* Eliminated duplicate account creation entirely.
* Simplified backend code by removing manual duplication checks.

**Lessons Learned / Future Steps**

* Always enforce data integrity at the database level, not just in application code.
* Combine unique constraints with proper error handling to return user-friendly messages.

---

### **Case Study 3 – Scalable Order ID Generation**

**Background**
A food delivery startup used `AUTO_INCREMENT` for `order_id` in a high-traffic ordering system.

**Problem**
During promotional campaigns, bulk inserts caused contention on the AUTO\_INCREMENT lock, reducing throughput.

**Multiple Team Efforts**

* **DBA** analyzed `innodb_autoinc_lock_mode`.
* **Backend team** batched inserts instead of single-row inserts.

**Code or Architectural Decisions**

```sql
SET GLOBAL innodb_autoinc_lock_mode = 2;
```

* Switched to **interleaved lock mode** for better parallel inserts.
* Introduced **order sharding** by city to distribute inserts across multiple tables.

**Broader Business Impact**

* Increased order insertion throughput by **40%** during peak events.
* Reduced order placement latency from **500 ms to under 100 ms**.

**Lessons Learned / Future Steps**

* AUTO\_INCREMENT is simple but can bottleneck under extreme concurrency.
* Consider sharding or using distributed ID generators (e.g., Snowflake IDs) for global scale.

---

### **Case Study 4 – Migrating from MyISAM to InnoDB for Unique Index Benefits**

**Background**
An analytics product stored large read-heavy tables in MyISAM.

**Problem**
MyISAM didn’t support transactions or foreign key constraints, and unique checks were slow for large datasets.

**Multiple Team Efforts**

* **DBA** migrated tables to InnoDB.
* **Backend team** adapted transaction handling.

**Code or Architectural Decisions**

```sql
ALTER TABLE metrics ENGINE=InnoDB;
CREATE UNIQUE INDEX idx_event_user ON metrics(event_id, user_id);
```

* Used a composite unique index to enforce event-user uniqueness.

**Broader Business Impact**

* Reduced data corruption incidents.
* Improved concurrent write performance.

**Lessons Learned / Future Steps**

* Always evaluate storage engine capabilities when designing schema constraints.
* Use composite unique indexes for multi-column uniqueness guarantees.

---

### <ins>STAR


### **S – Situation**

While working on a high-traffic e-commerce platform, our product search and checkout services began experiencing significant latency during peak sales events. Queries filtering products by category and brand were slow, and duplicate customer accounts were occasionally created during flash sales due to concurrency issues.

---

### **T – Task**

I needed to:

1. Optimize product listing queries to handle millions of rows efficiently.
2. Ensure that no duplicate accounts could be created, even under high concurrency.
3. Improve order ID generation performance, which was bottlenecked by `AUTO_INCREMENT` contention.

---

### **A – Action**

* **Index Optimization:**

  * Created a composite index on `(category_id, brand_id)` to match the most common filtering pattern.
  * Verified usage via `EXPLAIN ANALYZE` and adjusted query order to match index order.

* **Unique Constraint Enforcement:**

  * Added a `UNIQUE` constraint on the `email` column in the `users` table to enforce uniqueness at the DB level, eliminating race conditions.
  * Implemented proper error handling in backend code to gracefully inform users when email conflicts occur.

* **AUTO\_INCREMENT Performance Tuning:**

  * Changed `innodb_autoinc_lock_mode` from `1` to `2` to reduce contention.
  * Sharded `orders` table by region to distribute inserts across multiple sequences.

---

### **R – Result**

* Reduced product search query time from **\~1.8 seconds to \~35 ms** under full load.
* Completely eliminated duplicate user account creation.
* Increased order insertion throughput by **\~40%**, reducing checkout latency from **500 ms to under 100 ms** during campaigns.
* Enabled the system to handle **2x peak traffic** without additional database hardware.

---

### <ins>Code Samples: 



### 1) Canonical table with PK, UNIQUE, composite & covering index

```sql
CREATE TABLE users (
  id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
  email VARCHAR(255) NOT NULL,
  name VARCHAR(120) NOT NULL,
  created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (id),                                  -- clustered in InnoDB
  UNIQUE KEY uq_users_email (email),                 -- prevents duplicates
  KEY idx_users_created_at (created_at),             -- common filter/sort
  KEY idx_users_email_name (email, name)             -- covering SELECT email,name
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

---

### 2) Composite index to match filter pattern (e-commerce)

```sql
CREATE TABLE products (
  id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
  category_id INT NOT NULL,
  brand_id INT NOT NULL,
  price_cents INT NOT NULL,
  PRIMARY KEY (id),
  KEY idx_cat_brand_price (category_id, brand_id, price_cents)
) ENGINE=InnoDB;

-- Query shaped to use the index prefix and range:
SELECT id, price_cents
FROM products
WHERE category_id = ? AND brand_id = ? AND price_cents BETWEEN ? AND ?
ORDER BY price_cents;
```

---

### 3) Prefix index to speed lookups on long strings

```sql
CREATE TABLE articles (
  id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
  slug VARCHAR(768) NOT NULL,
  title VARCHAR(255) NOT NULL,
  UNIQUE KEY uq_slug_prefix (slug(191))  -- prefix to stay within index key length
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

---

### 4) Functional index via generated column (case-insensitive email)

```sql
CREATE TABLE accounts (
  id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
  email VARCHAR(255) NOT NULL,
  email_lc VARCHAR(255) AS (LOWER(email)) STORED,
  UNIQUE KEY uq_email_lc (email_lc)
) ENGINE=InnoDB;

-- Now queries can be sargable:
SELECT id FROM accounts WHERE email_lc = LOWER(?);
```

---

### 5) Full-Text search index (natural language search)

```sql
CREATE TABLE docs (
  id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
  title VARCHAR(255),
  body TEXT,
  FULLTEXT KEY ftx_title_body (title, body)
) ENGINE=InnoDB;

SELECT id, MATCH(title, body) AGAINST (? IN NATURAL LANGUAGE MODE) AS score
FROM docs
WHERE MATCH(title, body) AGAINST (? IN NATURAL LANGUAGE MODE)
ORDER BY score DESC
LIMIT 20;
```

---

### 6) Spatial index (GIS)

```sql
CREATE TABLE places (
  id BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
  name VARCHAR(255),
  location POINT NOT NULL SRID 4326,
  SPATIAL INDEX spx_location (location)
) ENGINE=InnoDB;

-- Bounding box example (fast with spatial index):
SELECT id, name
FROM places
WHERE MBRContains(ST_GeomFromText('POLYGON((...))', 4326), location);
```

---

### 7) Make an index invisible to test impact safely

```sql
ALTER TABLE users ALTER INDEX idx_users_created_at INVISIBLE;

-- Observe performance/plan without dropping the index.
-- Revert:
ALTER TABLE users ALTER INDEX idx_users_created_at VISIBLE;
```

---

### 8) Add / drop unique constraint (multi-column business rule)

```sql
ALTER TABLE order_items
  ADD CONSTRAINT uq_order_product UNIQUE (order_id, product_id);

ALTER TABLE order_items
  DROP INDEX uq_order_product;  -- drops the unique constraint’s backing index
```

---

### 9) “Upsert” with unique constraint (idempotent writes)

```sql
INSERT INTO users (email, name)
VALUES (?, ?)
ON DUPLICATE KEY UPDATE
  name = VALUES(name),          -- update on conflict
  updated_at = NOW();
```

---

### 10) Proving index usage (EXPLAIN / EXPLAIN ANALYZE)

```sql
EXPLAIN FORMAT=JSON
SELECT id FROM products
WHERE category_id = 5 AND brand_id = 12
ORDER BY price_cents
LIMIT 50;

EXPLAIN ANALYZE
SELECT id, email FROM users WHERE email = 'a@b.com';
```

---

### 11) Inspecting redundant/unused indexes

```sql
-- All indexes for a table
SELECT index_name, non_unique, seq_in_index, column_name
FROM information_schema.statistics
WHERE table_schema = DATABASE() AND table_name = 'users'
ORDER BY index_name, seq_in_index;

-- Basic heuristic for potential redundancy (same left-prefix)
-- (Evaluate manually; don't auto-drop)
```

---

### 12) AUTO\_INCREMENT: start value, gaps, and concurrency

```sql
-- Start at a specific value (e.g., post data migration)
ALTER TABLE orders AUTO_INCREMENT = 5000001;

-- Tune lock mode for bulk/parallel inserts:
-- 0=traditional, 1=consecutive (default), 2=interleaved (highest concurrency)
SET GLOBAL innodb_autoinc_lock_mode = 2;

-- Session-safe check
SHOW VARIABLES LIKE 'innodb_autoinc_lock_mode';
```

---

### 13) Multi-writer shard-safe AUTO\_INCREMENT (distinct sequences per node)

```sql
-- Node A (IDs: 1,4,7,...)          Node B (IDs: 2,5,8,...)        Node C (IDs: 3,6,9,...)
SET PERSIST auto_increment_increment = 3;
SET PERSIST auto_increment_offset     = 1;    -- A uses 1; B uses 2; C uses 3
```

---

### 14) UUID alternative with index-friendly storage

```sql
CREATE TABLE events (
  id BINARY(16) NOT NULL PRIMARY KEY,     -- compact 16 bytes
  payload JSON NOT NULL,
  created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
  KEY idx_created_at (created_at)
) ENGINE=InnoDB;

-- App-side (or MySQL function) generate UUID, store as binary for better index locality:
-- INSERT INTO events (id, payload) VALUES (UUID_TO_BIN(UUID(), 1), ?);
-- SELECT BIN_TO_UUID(id, 1) FROM events;
```

---

### 15) Covering index for hot read path

```sql
CREATE TABLE sessions (
  session_id CHAR(64) PRIMARY KEY,
  user_id BIGINT UNSIGNED NOT NULL,
  last_seen TIMESTAMP NOT NULL,
  device VARCHAR(64) NOT NULL,
  KEY idx_user_last_seen_device (user_id, last_seen, device)
) ENGINE=InnoDB;

-- Fully covered (no table lookup):
SELECT user_id, device, last_seen
FROM sessions
WHERE user_id = ?
ORDER BY last_seen DESC
LIMIT 50;
```

---

### 16) Lock/Contention visibility (unique checks, hot PK insert)

```sql
-- Current locks (high-level)
SELECT * FROM performance_schema.data_locks;

-- Who’s blocking whom
SELECT
  r.trx_id       AS waiting_trx,
  b.trx_id       AS blocking_trx,
  r.trx_state    AS waiting_state,
  b.trx_state    AS blocking_state
FROM information_schema.innodb_lock_waits w
JOIN information_schema.innodb_trx r ON w.requesting_trx_id = r.trx_id
JOIN information_schema.innodb_trx b ON w.blocking_trx_id  = b.trx_id;
```

---

### 17) Partitioning for time-series + index pruning

```sql
CREATE TABLE metrics (
  id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT,
  ts DATETIME NOT NULL,
  user_id BIGINT UNSIGNED NOT NULL,
  value DOUBLE NOT NULL,
  PRIMARY KEY (id, ts),  -- PK must include partition key
  KEY idx_ts_user (ts, user_id)
)
PARTITION BY RANGE COLUMNS (ts) (
  PARTITION p2025_07 VALUES LESS THAN ('2025-08-01'),
  PARTITION p2025_08 VALUES LESS THAN ('2025-09-01'),
  PARTITION pmax    VALUES LESS THAN (MAXVALUE)
) ENGINE=InnoDB;

-- Prunes partitions for time windows:
SELECT AVG(value)
FROM metrics
WHERE ts >= '2025-08-10' AND ts < '2025-08-17' AND user_id = ?;
```

---

### 18) Online index changes (zero/low downtime)

```bash
# Percona: online add/drop/rebuild without long blocking DDL
pt-online-schema-change \
  --alter "ADD INDEX idx_email_name (email, name)" \
  D=app,t=users --execute
```

---

### 19) Guardrails: drop truly redundant indexes

```sql
-- Example: if you already have KEY (email, name), then KEY (email) is often redundant
ALTER TABLE users DROP INDEX idx_email;  -- validate with workload before dropping
```

---

### <ins>CIQnA



## **1. Indexes**

**Q1:** *What’s the difference between a primary key index, unique index, and regular index in MySQL?*
**A:**

* **Primary Key Index**: Unique, non-null, and clustered in InnoDB (data stored in PK order).
* **Unique Index**: Ensures uniqueness, allows NULLs unless restricted, automatically indexed.
* **Regular Index**: Speeds lookups but no uniqueness enforcement.

---

**Q2:** *When would you use a composite index instead of separate single-column indexes?*
**A:**

* When queries filter by multiple columns together (`WHERE col1 = ? AND col2 = ?`).
* Composite indexes improve performance when column order matches query order and most selective column comes first.
* Separate indexes would require index merge, which is slower for high-cardinality joins.

---

**Q3:** *What is a covering index and why is it useful?*
**A:**

* An index that contains all the columns a query needs (both filter and select list).
* Avoids table lookups (extra I/O), speeds reads significantly.
* Example: `INDEX(user_id, last_seen, device)` covers `SELECT last_seen, device FROM sessions WHERE user_id=?`.

---

**Q4:** *What is the difference between a clustered and non-clustered index in MySQL?*
**A:**

* **Clustered Index**: Data is stored in the index itself (InnoDB primary key).
* **Non-clustered Index**: Stores pointers to data (or PK values in InnoDB) in separate index structure.

---

**Q5:** *What are the downsides of having too many indexes?*
**A:**

* Slows down `INSERT`, `UPDATE`, and `DELETE` because indexes must be updated.
* Consumes more storage.
* Can confuse optimizer into choosing suboptimal plans.

---

---

## **2. Unique Constraints**

**Q6:** *What’s the difference between a unique constraint and a unique index?*
**A:**

* Functionally, they both enforce uniqueness.
* **Unique constraint** is a schema-level integrity rule; MySQL implements it via a unique index.
* Constraints are more semantically expressive (integrity intent), indexes are primarily for performance.

---

**Q7:** *Can a unique constraint allow NULL values?*
**A:**

* Yes, MySQL allows one NULL per column in a unique constraint unless it’s also `NOT NULL`.

---

**Q8:** *How do you handle duplicate insert attempts when a unique constraint exists?*
**A:**

* Use `INSERT IGNORE` to skip duplicates.
* Or `INSERT ... ON DUPLICATE KEY UPDATE` to perform an upsert.
* Or catch the `Duplicate entry` error and handle in application logic.

---

**Q9:** *Why enforce uniqueness at the database level rather than in application code?*
**A:**

* Prevents race conditions under concurrency.
* Guarantees integrity even if multiple apps write to DB.
* Avoids relying on timing-sensitive checks.

---

---

## **3. AUTO\_INCREMENT**

**Q10:** *Can AUTO\_INCREMENT guarantee sequential, gapless IDs?*
**A:**

* No. Gaps can occur due to rollbacks, crashes, or deletes.
* If gapless sequence is required, use application-managed sequences with locking or a separate counter table.

---

**Q11:** *How do you avoid AUTO\_INCREMENT contention in high-write systems?*
**A:**

* Tune `innodb_autoinc_lock_mode` to `2` (interleaved) for batch inserts.
* Use sharding or separate tables per region.
* Consider distributed ID generators like Snowflake IDs or UUIDs.

---

**Q12:** *Can a table have more than one AUTO\_INCREMENT column?*
**A:**

* No, MySQL allows only one AUTO\_INCREMENT column per table.

---

**Q13:** *How do you start AUTO\_INCREMENT from a specific value?*
**A:**

```sql
ALTER TABLE orders AUTO_INCREMENT = 5000;
```

---

**Q14:** *What happens to AUTO\_INCREMENT after TRUNCATE?*
**A:**

* It resets to the starting value (usually 1 unless set otherwise).

---

---

## **4. Performance & Design Scenarios**

**Q15:** *If you have a table with billions of rows, how do you index it efficiently?*
**A:**

* Use selective indexes (avoid low-cardinality columns like `gender`).
* Consider composite indexes aligned with most frequent queries.
* Use covering indexes for hot read paths.
* Partition data to limit index size per partition.

---

**Q16:** *How do you find unused or redundant indexes?*
**A:**

* Use `performance_schema.table_io_waits_summary_by_index_usage` to detect zero-usage indexes.
* Compare left prefixes to drop redundant indexes.

---

**Q17:** *What’s the impact of indexing a TEXT or BLOB column?*
**A:**

* You must define a prefix length (`INDEX(col(100))`).
* Larger prefixes increase storage; smaller prefixes may cause more false positives requiring table lookups.

---

**Q18:** *How do you ensure index is used by a query?*
**A:**

* Match query predicates to index column order.
* Avoid wrapping indexed columns in functions.
* Use `EXPLAIN` or `EXPLAIN ANALYZE` to verify usage.

---

**Q19:** *When would you choose UUID over AUTO\_INCREMENT for a primary key?*
**A:**

* In distributed systems where multiple nodes insert concurrently.
* When you need globally unique IDs without coordination.
* Trade-off: Larger index size, worse clustering unless stored in binary & time-ordered format.

---

## **Follow-up & trick question set** :


## **1. Indexes – Follow-up Traps**

**Q1:** *You said composite indexes are good for multi-column queries. What if I have an index `(a, b, c)` — will it speed up `WHERE b = 5`?*
**A:**
No, unless `a` is also in the filter. MySQL can only use the leftmost prefix of an index unless it uses an index skip scan (which is rare and inefficient).
**Follow-up tip:** If you need `b`-only lookups often, add a separate index on `b`.

---

**Q2:** *How can indexes hurt query performance instead of help?*
**A:**

* The optimizer may choose the wrong index if statistics are stale.
* Low-selectivity indexes may cause random I/O without reducing rows scanned.
* Extra index maintenance slows down write-heavy workloads.
  **Follow-up trick:** Demonstrate how `FORCE INDEX` can help but is risky if the data distribution changes.

---

**Q3:** *If you have a covering index, can MySQL skip reading the table entirely?*
**A:**
Yes, if the query’s SELECT list + filter columns are all in the index. This is called an **index-only scan**.
**Follow-up trap:** InnoDB still needs to check visibility (MVCC) for each row unless it’s in a read-committed context.

---

---

## **2. Unique Constraints – Follow-up Traps**

**Q4:** *If a column has a unique constraint, will MySQL reject two NULL values?*
**A:**
No, in MySQL you can have multiple NULLs in a UNIQUE column (unless `NOT NULL` is specified).
**Follow-up trick:** Some DBs (like SQL Server) treat NULLs differently — knowing MySQL’s behavior shows precision.

---

**Q5:** *Can you enforce a unique constraint on an expression, like `LOWER(email)`?*
**A:**
Not directly, but you can use a generated column (`STORED`) and put a unique index on it.
**Follow-up trap:** If you use `VIRTUAL` generated columns, they can’t be indexed in all MySQL versions.

---

**Q6:** *How does MySQL ensure uniqueness under concurrent inserts?*
**A:**
MySQL uses index-level locking when checking uniqueness — a conflicting insert waits or fails.
**Follow-up trick:** If inserts are on different shards or partitions, the uniqueness check is local to that shard.

---

---

## **3. AUTO\_INCREMENT – Follow-up Traps**

**Q7:** *What happens to AUTO\_INCREMENT if you delete rows?*
**A:**
It doesn’t reuse deleted IDs unless you explicitly reset it with `ALTER TABLE ... AUTO_INCREMENT = value;`.
**Follow-up trap:** Even with reset, concurrent inserts may still jump ahead due to locking.

---

**Q8:** *You mentioned `innodb_autoinc_lock_mode`. Why not always set it to `2` for performance?*
**A:**
Mode `2` allows interleaved inserts but may break assumptions about consecutive IDs, especially in replication with `STATEMENT` mode — it can cause data drift.
**Follow-up trick:** In GTID-based replication, use `ROW` or `MIXED` format when using mode `2`.

---

**Q9:** *How do you avoid AUTO\_INCREMENT collisions in a multi-master replication setup?*
**A:**
Use different `auto_increment_increment` and `auto_increment_offset` values for each master.
**Follow-up trap:** This only works if the increment value covers all masters and offsets are unique.

---

---

## **4. Design & Edge-Case Pushes**

**Q10:** *If you have a table with `(user_id, order_date, amount)`, how would you index it for:*

1. Daily sales reports
2. User order history
   **A:**

* For daily sales → index `(order_date, user_id)` to support grouping by date.
* For user history → index `(user_id, order_date)` for fast range scans.
  **Follow-up trick:** You may need two separate indexes because optimal order differs.

---

**Q11:** *What’s the fastest way to find duplicates in a table?*
**A:**

```sql
SELECT email, COUNT(*) 
FROM users
GROUP BY email
HAVING COUNT(*) > 1;
```

**Follow-up trap:** This is slow for large data; better is to use a unique index and let violations surface during insert.

---

**Q12:** *How do you detect and drop truly unused indexes safely in production?*
**A:**

* Monitor `performance_schema.table_io_waits_summary_by_index_usage` for read counts.
* Drop after confirming zero usage across a full business cycle.
  **Follow-up trap:** Some indexes are rarely used but critical (e.g., disaster recovery queries).



