

#  **B-Tree (Balanced Tree)**

---

## üß† What is a B-Tree?

A **B-Tree** is a **self-balancing, multi-level search tree** used for organizing large datasets on disk. It maintains sorted data and allows **logarithmic time** complexity for **search, insert, and delete** operations.

It is ideal for **disk-based storage systems** like databases and file systems because it reduces disk I/O by keeping the tree shallow.

---

## üß¨ **B-Tree Properties (Order *m*)**

A B-Tree of **order *m*** (also called *m-way B-Tree*) follows these rules:

1. **Every node** can have **at most *m* children**.
2. **Every internal node** (non-leaf) has **at least ‚åàm/2‚åâ children**, except the root.
3. **Every node (except root)** contains at least **‚åàm/2‚åâ ‚àí 1 keys**.
4. **Each node** with *k* children has exactly **k ‚àí 1 keys**.
5. **All leaves appear at the same depth**.
6. **Keys within nodes are sorted in increasing order**.

---

## üì¶ **Structure of a B-Tree Node**

Each node contains:

* An array of **keys**: `K1 < K2 < K3 < ... < Kn`
* An array of **child pointers**: `C0, C1, ..., Cn`

  * All values in subtree `C0` are `< K1`
  * All values in subtree `Ci` are between `Ki` and `Ki+1`
  * All values in subtree `Cn` are `> Kn`

---

## üîç **Search Operation**

To search for key `K`:

1. Start at the root.
2. Perform binary or linear search within node keys.
3. If key is found ‚Üí return.
4. Else ‚Üí follow the pointer to the correct child and repeat.

### ‚è± Time Complexity:

* **O(log‚Çò N)**, where `N` is the number of keys and `m` is the order of the tree (i.e., fan-out).

---

## ‚ûï **Insertion Operation**

1. **Search** for the correct leaf node where key should be inserted.
2. **Insert** the key in sorted order.
3. If the node **overflows** (more than `m‚àí1` keys):

   * **Split** the node into two halves.
   * **Promote** the middle key to the parent node.
   * If parent overflows ‚Üí recursively split up to root.
4. If root splits ‚Üí create a new root.

### üìå Note:

This **preserves balance** and ensures **logarithmic depth**.

---

## ‚ûñ **Deletion Operation**

Deleting a key involves three cases:

1. **Key in leaf node (no underflow):** Remove directly.
2. **Key in internal node:** Replace with **in-order predecessor/successor**, then delete recursively.
3. **Underflow (fewer than ‚åàm/2‚åâ‚àí1 keys)**:

   * **Borrow** key from sibling (left/right) if it has more than minimum.
   * Else, **merge** with sibling and **pull down** a key from parent.

---

## üìã **Example (Order 4 B-Tree)**

```
         [17 | 35]
        /    |     \
   [5 10] [20 25] [40 50 60]
```

* Root has 2 keys ‚Üí 3 children
* Children have 2 or 3 keys (within allowed limits)
* All leaves are at the same level

---

## ‚úÖ **Advantages of B-Trees**

| Feature                | Description                                           |
| ---------------------- | ----------------------------------------------------- |
| **Shallow height**     | Reduces disk I/O due to fewer node accesses           |
| **Balanced structure** | Keeps search time logarithmic                         |
| **Efficient inserts**  | Handles large datasets without rebalancing whole tree |
| **Disk-friendly**      | Nodes can match disk block size to minimize I/O       |

---

## ‚ùå **Disadvantages**

* Slightly slower for in-memory search compared to binary search trees.
* Complex deletion and merging logic.
* Internal nodes store both keys and values, increasing memory usage compared to B+ Trees.

---

## üÜö **B-Tree vs Binary Search Tree (BST)**

| Feature           | B-Tree                | BST                      |
| ----------------- | --------------------- | ------------------------ |
| Children per node | `m` (multi-way)       | 2 (binary)               |
| Tree height       | Logarithmic (shallow) | Can become skewed (deep) |
| Disk optimized    | ‚úÖ Yes                 | ‚ùå No                     |
| Balanced          | Always                | Not always               |

---

## üÜö **B-Tree vs B+ Tree**

| Feature                | B-Tree                | B+ Tree                            |
| ---------------------- | --------------------- | ---------------------------------- |
| Data in internal nodes | ‚úÖ Yes                 | ‚ùå No (only in leaves)              |
| Range queries          | Slower                | Faster (linked leaves)             |
| Sequential access      | ‚ùå Not efficient       | ‚úÖ Very efficient                   |
| Space overhead         | Less (no duplication) | Slightly more (keys repeated)      |
| Common usage           | Rare                  | Widely used in DBMS & file systems |

---

## üîß **Use Cases of B-Trees**

* Indexing in older DBMS
* File systems (e.g., NTFS, HFS+)
* Sorted associative containers in memory
* Searching large blocks in external memory (e.g., SSD/HDD)

---

## üß† Summary

* B-Trees are **generalized BSTs** designed for **disk access efficiency**.
* They maintain a balanced, shallow structure to optimize **search, insert, and delete**.
* Ideal when the cost of disk I/O dominates performance.


----------

## Real world use case: 

Let‚Äôs walk through a **real, practical B-tree (actually B+-tree) example** like what MySQL/InnoDB uses to index a table.

# 1) The real-world setup

```sql
CREATE TABLE accounts (
  id BIGINT PRIMARY KEY,     -- clustered B+-tree on id
  owner VARCHAR(100),
  balance DECIMAL(12,2)
) ENGINE=InnoDB;
```

* InnoDB stores rows **physically ordered by the primary key** in a **clustered B+-tree**.
* Each node is a **disk page** (InnoDB default: 16 KB).
* **Internal pages** hold **separator keys** and child pointers.
* **Leaf pages** hold **actual rows** (the payload) in key order and are **linked** left‚Üîright for fast range scans.

For illustration we‚Äôll pretend each page can hold only a few keys so you can see splits clearly.

# 2) What a snapshot looks like

```
Root (internal):              [ 1000 | 2000 | 3000 ]
                         /        |         |        \
                    p0           p1        p2        p3
```

Leaf pages (linked list at the bottom):

```
p0: [ 101, 220, 450, 760, 995 ]
p1: [ 1000, 1210, 1735, 1998 ]
p2: [ 2001, 2105, 2200, 2250, 2600, 2990 ]
p3: [ 3001, 3450, 4000, 5010 ]
```

(Arrows between leaves:  p0 ‚Üî p1 ‚Üî p2 ‚Üî p3 )

# 3) Point lookup (e.g., `SELECT * FROM accounts WHERE id=1735`)

1. **Read Root** ‚Üí keys `[1000 | 2000 | 3000]`.
   `1735` is between `1000` and `2000` ‚áí go to child **p1**.
2. **Read p1 (leaf)** ‚Üí it‚Äôs sorted; binary search finds `1735`.
   **I/Os** ‚âà 2 page reads (root + one leaf). In a big index you might add one more internal level, but the height stays tiny.

# 4) Range query (e.g., `WHERE id BETWEEN 2100 AND 2250`)

1. Descend to the **first leaf** that could contain `2100` (from root ‚Üí **p2**).
2. Inside **p2**, binary search to the first ‚â• 2100 (`2105`) and **scan forward in the leaf**: `2105, 2200, 2250`.
3. If the range spills to the next page, follow the **leaf next-pointer** to the right.
   This is why B+-trees are fantastic for `ORDER BY id` and range queries.

# 5) Insert (e.g., `INSERT (2255, ...)`)

* Find the target leaf (**p2**). If it has room, slide keys and insert `2255` in order.
* **If the leaf is full**, it **splits** roughly in half:

Before:

```
p2: [ 2001, 2105, 2200, 2250, 2600, 2990 ]  (full)
```

After split:

```
p2:       [ 2001, 2105, 2200 ]       ‚Üí next ‚Üí   p2' : [ 2250, 2600, 2990, 2255(sorted to [2250,2255,2600,2990]) ]
```

* A **separator key** (here `2250` or `2255` depending on implementation) is **promoted** up to the parent to route future searches.
* If the **parent page** is full, the split **bubbles up**; in the worst case the **root splits**, increasing height by 1. This is rare, which is why B-trees stay shallow.

# 6) Delete (e.g., `DELETE WHERE id=1000`)

* Remove `1000` from leaf **p1**.
* If the leaf falls **below minimum occupancy**, it tries to **borrow** a key from a sibling; otherwise it **merges** with a sibling and updates the parent separator.
  This keeps pages reasonably full and the tree balanced.

# 7) Why it‚Äôs so fast in practice

* **Huge fan-out**: a 16 KB internal page can guide to **hundreds** of children.
  That means **millions of rows** often fit in a tree of **height \~3‚Äì4**, so point lookups are \~3‚Äì4 random page reads.
* **Sequential leaves** make ordered scans and ranges cache- and disk-friendly.

# 8) Seeing it in your database (hands-on ideas)

* **MySQL/InnoDB**: primary key is clustered; secondary indexes are separate B+-trees whose **leaf** stores `(secondary_key ‚Üí primary_key)` and then InnoDB fetches the row by PK if needed (a ‚Äúback to the clustered index‚Äù lookup).
* Try:

  ```sql
  EXPLAIN SELECT * FROM accounts WHERE id = 1735;
  EXPLAIN SELECT * FROM accounts WHERE id BETWEEN 2100 AND 2250 ORDER BY id;
  ```

  You‚Äôll see index usage and range scans.
* Fill a table with many rows, then compare:

  ```sql
  -- With index:
  SELECT SQL_NO_CACHE * FROM accounts WHERE id=1735;
  -- Without index (after dropping it), compare execution time & handler reads.
  ```

# 9) A non-DB real example (just to relate)

* **File systems** (APFS, Btrfs, NTFS directories) and **key-value stores** (like LMDB) use B/B+-trees so that directory lookups, inserts, and sorted listings stay fast with few disk seeks.

---

## B-tree example: 

Here‚Äôs a concrete **B-tree example** with **minimum degree `t = 2`** (also called *order 4*, i.e., each node can have up to 3 keys and up to 4 children).

### Keys inserted (in order)

`10, 20, 5, 6, 12, 30, 7, 17`

### How it evolves (major steps)

1. Start with empty tree ‚Üí insert `10` ‚Üí `[10]`

2. Insert `20` ‚Üí `[10 | 20]`

3. Insert `5`  ‚Üí `[5 | 10 | 20]` (root is now full)

4. Insert `6`:

   * Root is full, so **split** it around `10`.
     New root: `[10]` with children `[5]` and `[20]`.
   * Insert `6` into left child ‚Üí `[5 | 6]`.

5. Insert `12` ‚Üí goes to right child: `[12 | 20]`

6. Insert `30` ‚Üí right child: `[12 | 20 | 30]` (full, but allowed for now)

7. Insert `7`  ‚Üí left child: `[5 | 6 | 7]`

8. Insert `17`:

   * Before descending, notice right child `[12 | 20 | 30]` is full ‚Üí **split** around `20`.
     Promote `20` to root. Right child becomes two nodes: `[12]` and `[30]`.
     Root becomes `[10 | 20]` with children: `[5|6|7]`, `[12]`, `[30]`.
   * Insert `17` into middle child `[12]` ‚Üí `[12 | 17]`.

### Final B-tree

```
              [ 10 | 20 ]
              /    |     \
        [5 | 6 | 7] [12 | 17] [30]
```

* **Internal node** `[10 | 20]` uses keys as **separators**.
* **Leaves** hold the actual keys (and, in a database B-tree, pointers/payloads).

### Example lookups

* Search `17`: root `[10|20]` ‚Üí between 10 and 20 ‚Üí middle child ‚Üí found in `[12|17]`.
* Search `6`: root `[10|20]` ‚Üí left child ‚Üí found in `[5|6|7]`.

If you want, I can run the same sequence with a different `t` (like `t=3`) to show a wider, shallower tree and different split points.


