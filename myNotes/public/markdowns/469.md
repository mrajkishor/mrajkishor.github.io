Here‚Äôs the solution for [**LeetCode 2636 ‚Äì Cache With Time Limit**](https://leetcode.com/problems/cache-with-time-limit/description/?envType=study-plan-v2&envId=30-days-of-javascript):

---

## ‚úÖ Problem Summary

You‚Äôre given a function `fn` and a time limit `t`.  
Return a **memoized version of `fn`** such that:

- If the memoized function is called with **the same arguments** within `t` milliseconds, return the **cached result**
- Otherwise, call `fn` again and **refresh the cache**

---

## ‚úÖ Solution (Using `Map` and `setTimeout`)

```ts
function timeLimitCache(fn: (...args: any[]) => any, t: number): (...args: any[]) => any {
  const cache = new Map<string, { value: any; expiry: number }>();

  return (...args: any[]) => {
    const key = JSON.stringify(args);
    const now = Date.now();

    const entry = cache.get(key);

    if (entry && now < entry.expiry) {
      return entry.value;
    }

    const result = fn(...args);
    cache.set(key, { value: result, expiry: now + t });

    return result;
  };
}
```

---

## ‚úÖ Example Usage

```ts
const cached = timeLimitCache((a, b) => a + b, 5000);

console.log(cached(2, 3)); // 5 (calculated)
console.log(cached(2, 3)); // 5 (from cache within 5s)

setTimeout(() => {
  console.log(cached(2, 3)); // 5 (recomputed after 5s)
}, 6000);
```

---

## üß† How It Works

- `Map<string, { value, expiry }>` stores results by JSON-stringified args
- On each call:
  - If cached & not expired ‚Üí return cached
  - Else ‚Üí compute, store, and return

---

## üß™ Edge Considerations

- Assumes `fn` is **synchronous**
- If `fn` is async, you need to cache Promises too

---

## Class variant 

Here's a full solution for the **TimeLimitedCache** class ‚Äî as required in LeetCode [**2638. Time Limited Cache**](https://leetcode.com/problems/time-limited-cache/description/):

---

## ‚úÖ Requirements Recap

- `.set(key, value, duration)` ‚Üí sets value for `key` with expiry in `duration` ms.  
  Returns `true` if key already exists and hasn‚Äôt expired, else `false`.
- `.get(key)` ‚Üí returns value if not expired, else `-1`.
- `.count()` ‚Üí returns count of **non-expired** keys.

---

## ‚úÖ Full Solution (in TypeScript/JavaScript)

```ts
class TimeLimitedCache {
  private cache: Map<number, { value: number; expiresAt: number }> = new Map();

  set(key: number, value: number, duration: number): boolean {
    const now = Date.now();
    const isValid = this.cache.has(key) && this.cache.get(key)!.expiresAt > now;

    this.cache.set(key, {
      value,
      expiresAt: now + duration,
    });

    return isValid;
  }

  get(key: number): number {
    const entry = this.cache.get(key);
    const now = Date.now();

    if (!entry || entry.expiresAt <= now) {
      this.cache.delete(key); // cleanup if expired
      return -1;
    }

    return entry.value;
  }

  count(): number {
    const now = Date.now();
    let count = 0;

    for (const [key, { expiresAt }] of this.cache) {
      if (expiresAt > now) count++;
      else this.cache.delete(key); // cleanup expired
    }

    return count;
  }
}
```

---

## ‚úÖ Example Test Case

```ts
const cache = new TimeLimitedCache();

console.log(cache.set(1, 42, 1000)); // false
console.log(cache.get(1));          // 42
console.log(cache.count());         // 1

setTimeout(() => {
  console.log(cache.get(1));       // -1 (expired)
  console.log(cache.count());      // 0
}, 1100);
```




---

## Extra

Here‚Äôs an **async-safe version** of the `timeLimitCache()` function ‚Äî suitable for caching the result of **Promise-returning functions** with a TTL (time-to-live):

---

## ‚úÖ Async-Safe TTL Memoization Function

```ts
function memoizeWithTTL<T extends (...args: any[]) => Promise<any>>(fn: T, ttl: number): T {
  const cache = new Map<string, { promise: Promise<any>; expiry: number }>();

  return (async (...args: any[]) => {
    const key = JSON.stringify(args);
    const now = Date.now();

    const cached = cache.get(key);

    if (cached && now < cached.expiry) {
      return cached.promise;
    }

    const resultPromise = fn(...args);
    cache.set(key, { promise: resultPromise, expiry: now + ttl });

    return resultPromise;
  }) as T;
}
```

---

## ‚úÖ Example Usage

```ts
const fetchUser = async (id: number) => {
  console.log(`Fetching user ${id}`);
  return { id, name: "User" + id };
};

const cachedFetchUser = memoizeWithTTL(fetchUser, 3000);

cachedFetchUser(1).then(console.log); // Fetches
cachedFetchUser(1).then(console.log); // From cache (within 3s)

setTimeout(() => {
  cachedFetchUser(1).then(console.log); // Fetches again (after expiry)
}, 4000);
```

---

## ‚úÖ Key Differences from Sync Version

| Feature         | Sync Version     | Async Version                    |
|----------------|------------------|----------------------------------|
| Result cached  | `value`          | `promise`                        |
| Return value   | plain            | always returns a `Promise`       |
| TTL            | same mechanism   | applies to promise start time    |
| Use case       | fast utils       | network/API/database functions   |

---

Here‚Äôs an **enhanced async-safe memoization utility** that supports:

‚úÖ Caching **errors**  
‚úÖ Optional `maxSize` limit for LRU-like behavior  
‚úÖ Optional TTL expiration (default behavior)

---

## ‚úÖ Enhanced Version: `memoizeWithTTL(fn, ttl, options)`

```ts
interface CacheEntry {
  promise: Promise<any>;
  expiry: number;
}

interface MemoizeOptions {
  maxSize?: number; // maximum entries in cache
  cacheErrors?: boolean; // whether to store rejected promises
}

export function memoizeWithTTL<T extends (...args: any[]) => Promise<any>>(
  fn: T,
  ttl: number,
  options: MemoizeOptions = {}
): T {
  const cache = new Map<string, CacheEntry>();

  function setCache(key: string, promise: Promise<any>) {
    const expiry = Date.now() + ttl;
    cache.set(key, { promise, expiry });

    // Respect maxSize: evict oldest
    if (options.maxSize && cache.size > options.maxSize) {
      const firstKey = cache.keys().next().value;
      cache.delete(firstKey);
    }

    // If caching errors is disabled
    if (!options.cacheErrors) {
      promise.catch(() => {
        if (cache.get(key)?.promise === promise) {
          cache.delete(key);
        }
      });
    }
  }

  return (async (...args: any[]) => {
    const key = JSON.stringify(args);
    const now = Date.now();

    const cached = cache.get(key);
    if (cached && now < cached.expiry) {
      return cached.promise;
    }

    const newPromise = fn(...args);
    setCache(key, newPromise);
    return newPromise;
  }) as T;
}
```

---

## üß™ Example Usage

```ts
const fetchWithError = async (id: number) => {
  if (id === 0) throw new Error("Fail");
  return { id };
};

const cached = memoizeWithTTL(fetchWithError, 3000, {
  cacheErrors: true,
  maxSize: 100
});

cached(1).then(console.log);      // stores and returns
cached(1).then(console.log);      // uses cache

cached(0).catch(console.error);   // stores error if enabled
```

---

## üîç Behavior Summary

| Feature         | Enabled?        | Notes                           |
|----------------|------------------|----------------------------------|
| Error Caching   | ‚úÖ Optional      | Keeps rejection in cache         |
| Max Size        | ‚úÖ Optional      | Evicts oldest entry (FIFO style) |
| TTL             | ‚úÖ Always        | Each entry has expiry timestamp  |

---

Next, we‚Äôll discuss:

‚úÖ An LRU-style cache implementation  
‚úÖ A sync-compatible version of `memoizeWithTTL`  

---

## An LRU-style cache implementation

Here's the **async LRU-based memoization utility with TTL and error caching** ‚Äî robust, efficient, and reusable:

---

## ‚úÖ `memoizeAsyncLRU(fn, options)`

```ts
interface AsyncMemoOptions {
  ttl?: number;             // Time to live in milliseconds
  maxSize?: number;         // Max number of cached entries
  cacheErrors?: boolean;    // Whether to cache rejected promises
}

export function memoizeAsyncLRU<T extends (...args: any[]) => Promise<any>>(
  fn: T,
  options: AsyncMemoOptions = {}
): T {
  const {
    ttl = 60000,
    maxSize = 100,
    cacheErrors = false
  } = options;

  const cache = new Map<string, { promise: Promise<any>; expiry: number }>();

  const updateLRU = (key: string) => {
    const entry = cache.get(key);
    cache.delete(key);        // remove and re-insert to update recency
    if (entry) cache.set(key, entry);
  };

  const evictIfNeeded = () => {
    while (cache.size > maxSize) {
      const oldestKey = cache.keys().next().value;
      cache.delete(oldestKey);
    }
  };

  return (async (...args: any[]) => {
    const key = JSON.stringify(args);
    const now = Date.now();

    const cached = cache.get(key);
    if (cached && now < cached.expiry) {
      updateLRU(key);
      return cached.promise;
    }

    const promise = fn(...args);
    const expiry = now + ttl;

    cache.set(key, { promise, expiry });
    evictIfNeeded();

    if (!cacheErrors) {
      promise.catch(() => {
        if (cache.get(key)?.promise === promise) {
          cache.delete(key);
        }
      });
    }

    return promise;
  }) as T;
}
```

---

## ‚úÖ Example Usage

```ts
const fetchUser = async (id: number) => {
  console.log("Fetching user", id);
  return { id, name: `User ${id}` };
};

const memoFetch = memoizeAsyncLRU(fetchUser, {
  ttl: 3000,
  maxSize: 50,
  cacheErrors: true
});

memoFetch(1).then(console.log); // Fetches
memoFetch(1).then(console.log); // Cached
```

---

## üìå Features Recap

| Feature           | ‚úÖ Support |
|------------------|------------|
| TTL expiration    | ‚úÖ         |
| LRU eviction      | ‚úÖ         |
| Error caching     | ‚úÖ         |
| Async support     | ‚úÖ         |

---

## A sync-compatible version of `memoizeWithTTL` 

Here‚Äôs the **sync-compatible version** of `memoizeWithTTL()` using **LRU eviction** and **optional TTL**:

---

## ‚úÖ `memoizeSyncLRU(fn, options)`

```ts
interface SyncMemoOptions {
  ttl?: number;       // Time to live in milliseconds
  maxSize?: number;   // Max number of cache entries
}

export function memoizeSyncLRU<T extends (...args: any[]) => any>(
  fn: T,
  options: SyncMemoOptions = {}
): T {
  const {
    ttl = 60000,
    maxSize = 100
  } = options;

  const cache = new Map<string, { value: any; expiry: number }>();

  const updateLRU = (key: string) => {
    const entry = cache.get(key);
    if (!entry) return;
    cache.delete(key);
    cache.set(key, entry);
  };

  const evictIfNeeded = () => {
    while (cache.size > maxSize) {
      const oldestKey = cache.keys().next().value;
      cache.delete(oldestKey);
    }
  };

  return ((...args: any[]) => {
    const key = JSON.stringify(args);
    const now = Date.now();

    const cached = cache.get(key);
    if (cached && now < cached.expiry) {
      updateLRU(key);
      return cached.value;
    }

    const result = fn(...args);
    const expiry = now + ttl;

    cache.set(key, { value: result, expiry });
    evictIfNeeded();

    return result;
  }) as T;
}
```

---

## ‚úÖ Example Usage

```ts
const multiply = (a: number, b: number) => {
  console.log("Computing...");
  return a * b;
};

const memoMultiply = memoizeSyncLRU(multiply, {
  ttl: 5000,
  maxSize: 10
});

console.log(memoMultiply(2, 3)); // logs "Computing..." then 6
console.log(memoMultiply(2, 3)); // cached, just logs 6
```

---

## üîç Comparison

| Feature         | Sync Version     | Async Version    |
|----------------|------------------|------------------|
| Caches result   | ‚úÖ                | ‚úÖ (promise)      |
| TTL support     | ‚úÖ                | ‚úÖ                |
| LRU eviction    | ‚úÖ                | ‚úÖ                |
| Error handling  | ‚ùå not needed     | ‚úÖ configurable   |

